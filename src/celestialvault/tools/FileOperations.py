import hashlib
import re
import shutil
import tarfile
import zipfile
from collections import defaultdict
from pathlib import Path
from typing import Any, Callable, Dict, List, Tuple

import py7zr
import rarfile
from tqdm import tqdm
from wcwidth import wcswidth
from celestialflow import TaskManager

from ..constants import IMG_SUFFIXES, VIDEO_SUFFIXES
from ..instances.inst_units import HumanBytes
from .TextTools import format_table


class HandleFileManager(TaskManager):
    def __init__(
        self,
        func: Callable,
        folder_path: Path,
        new_folder_path: Path,
        rules: Dict[str, Tuple[Callable, Callable]],
        execution_mode: str,
        progress_desc: str,
    ):
        super().__init__(
            func=func,
            execution_mode=execution_mode,
            worker_limit=6,
            max_info=100,
            enable_result_cache=True,
            progress_desc=progress_desc,
            show_progress=True,
        )
        self.folder_path = folder_path
        self.new_folder_path = new_folder_path
        self.rules = rules

    def get_args(self, file_path: Path):
        rel_path = file_path.relative_to(self.folder_path)
        new_file_path = self.new_folder_path / rel_path

        file_suffix = file_path.suffix.lower()
        action_func, rename_func, args_extra = self.rules.get(
            file_suffix, (shutil.copy2, lambda x: x, {})
        )

        final_path = rename_func(new_file_path)
        return (file_path, final_path, action_func, args_extra)

    def process_result(self, file_path: Path, result):
        return

    def handle_error_dict(self):
        error_path_dict = defaultdict(list)

        for file_path, error in self.get_error_dict().items():
            rel_path = file_path.relative_to(self.folder_path)
            new_file_path = self.new_folder_path / rel_path
            shutil.copy(file_path, new_file_path)
            error_path_dict[(type(error).__name__, str(error))].append(new_file_path)
        return dict(error_path_dict)
    

class HandleSubFolderManager(HandleFileManager):
    def get_args(self, sub_folder_path: Path):
        rel_path = sub_folder_path.relative_to(self.folder_path)
        new_sub_folder_path = self.new_folder_path / rel_path

        action_func, rename_func, args_extra = self.rules.get(
            'folder', (shutil.copy, lambda x: x, {})
        )

        final_path = rename_func(new_sub_folder_path)
        return (sub_folder_path, final_path, action_func, args_extra)
    
    def handle_error_dict(self):
        error_path_dict = defaultdict(list)

        for file_path, error in self.get_error_dict().items():
            rel_path = file_path.relative_to(self.folder_path)
            new_file_path = self.new_folder_path / rel_path
            # shutil.copy(file_path, new_file_path)
            error_path_dict[(type(error).__name__, str(error))].append(new_file_path)
        return dict(error_path_dict)


class ScanSizeManager(TaskManager):
    def process_result_dict(self):
        size_dict = defaultdict(list)

        for path, size in self.get_success_dict().items():
            size_dict[size].append(path)

        size_dict = {k: v for k, v in size_dict.items() if len(v) > 1}
        file_size_iter = (
            (file_path, size)
            for size, files in size_dict.items()
            for file_path in files
        )
        return file_size_iter


class ScanHashManager(TaskManager):
    def get_args(self, task):
        return (task[0],)

    def process_result_dict(self):
        identical_dict = defaultdict(list)

        for (path, size), hash_value in self.get_success_dict().items():
            identical_dict[(hash_value, size)].append(path)

        identical_dict = {k: v for k, v in identical_dict.items() if len(v) > 1}
        return identical_dict


class DeleteManager(TaskManager):
    def __init__(self, func, parent_dir: Path):
        super().__init__(func, progress_desc="Delete files/folders", show_progress=True)
        self.parent_dir = parent_dir

    def get_args(self, rel_path):
        target = self.parent_dir / rel_path
        return (target,)


class CopyManager(TaskManager):
    def __init__(self, func, main_dir: Path, minor_dir: Path, copy_mode: str):
        super().__init__(
            func, progress_desc=f"Copy files/folders[{copy_mode}]", show_progress=True
        )
        self.main_dir = main_dir
        self.minor_dir = minor_dir

    def get_args(self, rel_path: Path):
        source = self.main_dir / rel_path
        target = self.minor_dir / rel_path
        target.parent.mkdir(parents=True, exist_ok=True)
        return (source, target)


class DeleteReturnSizeManager(TaskManager):
    def process_result_dict(self):
        delete_size = 0
        for size in self.get_success_dict().values():
            delete_size += size
        return HumanBytes(delete_size)


def create_folder(path: str | Path) -> Path:
    """
    åˆ¤æ–­ç³»ç»Ÿæ˜¯å¦å­˜åœ¨è¯¥è·¯å¾„,æ²¡æœ‰åˆ™åˆ›å»ºã€‚

    :param path: è¦åˆ›å»ºçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: åˆ›å»ºæˆ–å­˜åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    path = Path(path)  # å°†è¾“å…¥è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡

    while True:
        try:
            if not path.exists():
                path.mkdir(parents=True)  # åˆ›å»ºç›®å½•,åŒ…æ‹¬ä»»ä½•å¿…è¦çš„çˆ¶ç›®å½•
            break
        except FileNotFoundError as e:
            print(e, path)
            path = path.parent  # ç§»é™¤æœ€åä¸€ä¸ªè·¯å¾„ç»„ä»¶
            continue

    return path


def handle_item(source: Path, destination: Path, action: Callable[[Path, Path, Any], Any], extra: dict):
    """
    å¤„ç†æ–‡ä»¶ï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨åˆ™æ‰§è¡ŒæŒ‡å®šçš„æ“ä½œã€‚

    :param source: æºæ–‡ä»¶è·¯å¾„ã€‚
    :param destination: ç›®æ ‡æ–‡ä»¶è·¯å¾„ã€‚
    :param action: å¤„ç†æ–‡ä»¶çš„å‡½æ•°æˆ–æ–¹æ³•ã€‚
    :return: å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™è¿”å› Noneï¼›å¦åˆ™è¿”å› action çš„ç»“æœã€‚
    """
    if destination.exists():
        return f"{destination} already exists."

    # åˆ¤æ–­ destination æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
    if destination.suffix:
        destination.parent.mkdir(parents=True, exist_ok=True)
    else:
        destination.mkdir(parents=True, exist_ok=True)
    action_result = action(source, destination, **extra)
    return action_result


def handle_folder_files(
    folder_path: str | Path,
    rules: Dict[str, Tuple[Callable[[Path, Path, Dict], None], Callable[[Path], Path]]],
    execution_mode: str = "serial",
    progress_desc: str = "Processing files",
    folder_name_suffix: str = "_re",
) -> Dict[Tuple[str, str], List[Path]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    ä¸å±äºæŒ‡å®šåç¼€çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚å¤„ç†åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚
    å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param rules: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åç¼€ï¼Œå€¼ä¸ºå¤„ç†è¯¥ç±»å‹æ–‡ä»¶çš„å‡½æ•°å’Œé‡å‘½åå‡½æ•°çš„å…ƒç»„ã€‚
    :param execution_mode: æ‰§è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 'serial' æˆ– 'thread' 'process'ã€‚é»˜è®¤ä¸º 'serial'ã€‚
    :param progress_desc: è¿›åº¦æ¡æè¿°ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    folder_path = Path(folder_path)
    new_folder_path = folder_path.parent / (folder_path.name + folder_name_suffix)

    handlefile_manager = HandleFileManager(
        func=handle_item,
        folder_path=folder_path,
        new_folder_path=new_folder_path,
        rules=rules,
        execution_mode=execution_mode,
        progress_desc=progress_desc,
    )

    file_path_iter = (
        file_path for file_path in folder_path.glob("**/*") if file_path.is_file()
    )
    handlefile_manager.start(file_path_iter)

    error_path_dict = handlefile_manager.handle_error_dict()
    return error_path_dict

def handle_subfolders(
    folder_path: str | Path,
    rules: Dict[str, Tuple[Callable[[Path, Path, Dict], None], Callable[[Path], Path]]],
    execution_mode: str = "serial",
    progress_desc: str = "Processing folders",
    folder_name_suffix: str = "_re",
) -> Dict[Tuple[str, str], List[Path]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    ä¸å±äºæŒ‡å®šåç¼€çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚å¤„ç†åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚
    å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param rules: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åç¼€ï¼Œå€¼ä¸ºå¤„ç†è¯¥ç±»å‹æ–‡ä»¶çš„å‡½æ•°å’Œé‡å‘½åå‡½æ•°çš„å…ƒç»„ã€‚
    :param execution_mode: æ‰§è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 'serial' æˆ– 'thread' 'process'ã€‚é»˜è®¤ä¸º 'serial'ã€‚
    :param progress_desc: è¿›åº¦æ¡æè¿°ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    folder_path = Path(folder_path)
    new_folder_path = folder_path.parent / (folder_path.name + folder_name_suffix)

    handlefile_manager = HandleSubFolderManager(
        func=handle_item,
        folder_path=folder_path,
        new_folder_path=new_folder_path,
        rules=rules,
        execution_mode=execution_mode,
        progress_desc=progress_desc,
    )

    sub_folder_list = find_pure_folders(folder_path, True)
    handlefile_manager.start(sub_folder_list)

    error_path_dict = handlefile_manager.handle_error_dict()
    return error_path_dict

def compress_folder(
    folder_path: str | Path, execution_mode: str = "thread"
) -> List[Tuple[Path, Exception]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå‹ç¼©å¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬å›¾ç‰‡ã€è§†é¢‘å’ŒPDFã€‚ä¸å±äºè¿™ä¸‰ç§ç±»å‹çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚
    å‹ç¼©åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param execution_mode: æ‰§è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 'serial' æˆ– 'thread' 'process'ã€‚é»˜è®¤ä¸º 'thread'ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """

    def rename_mp4(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        suffix = file_path.suffix.lstrip(".")
        new_name = f"{name}_compressed({suffix}).mp4"
        return file_path.with_name(new_name)

    def rename_pdf(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        new_name = f"{name}_compressed.pdf"
        return file_path.with_name(new_name)

    from .ImageProcessing import compress_img
    from .VideoProcessing import compress_video
    # from .DocumentConversion import compress_pdf

    rules = {suffix: (compress_img, lambda x: x, {}) for suffix in IMG_SUFFIXES}
    rules.update({suffix: (compress_video, rename_mp4, {}) for suffix in VIDEO_SUFFIXES})
    # rules.update({'.pdf': (compress_pdf,rename_pdf, {})})

    return handle_folder_files(
        folder_path, rules, execution_mode, progress_desc="Compressing Folder"
    )


def unzip_zip_file(zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ zip æ–‡ä»¶ã€‚

    :param zip_file: è¦è§£å‹ç¼©çš„ zip æ–‡ä»¶è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ zip æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    try:
        with zipfile.ZipFile(zip_file) as zip_file:
            zip_file.extractall(destination)
    except zipfile.BadZipFile:
        raise ValueError(f"{zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ zip æ–‡ä»¶")
    except zipfile.LargeZipFile:
        raise ValueError(f"{zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except RuntimeError:
        raise ValueError("{zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")


def unzip_rar_file(rar_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ rar æ–‡ä»¶ã€‚

    :param rar_file: è¦è§£å‹ç¼©çš„ rar æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with rarfile.RarFile(rar_file) as rar_file:
            rar_file.extractall(destination)
    except rarfile.BadRarFile:
        raise ValueError(f"{rar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ rar æ–‡ä»¶")
    except rarfile.LargeRarFile:
        raise ValueError(f"{rar_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except rarfile.PasswordRequired:
        raise ValueError(f"{rar_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")


def unzip_tar_file(tar_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ tar æ–‡ä»¶ã€‚

    :param tar_file: è¦è§£å‹ç¼©çš„ tar æ–‡ä»¶è·¯å¾„ã€‚
    :param destination: è§£å‹ç¼©çš„ç›®æ ‡è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ tar æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ tar æ–‡ä»¶
    if not tarfile.is_tarfile(tar_file):
        raise ValueError(f"{tar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ tar æ–‡ä»¶")
    try:
        # æ‰“å¼€ tar æ–‡ä»¶
        with tarfile.open(tar_file) as tar:
            # æå–æ‰€æœ‰å†…å®¹åˆ°ç›®æ ‡è·¯å¾„
            tar.extractall(path=destination)
    except tarfile.ReadError:
        raise ValueError(f"{tar_file} è¯»å–é”™è¯¯ï¼Œå¯èƒ½ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ tar æ–‡ä»¶")
    except Exception as e:
        raise ValueError(f"è§£å‹ {tar_file} æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def unzip_7z_file(seven_zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ 7z æ–‡ä»¶ã€‚

    :param seven_zip_file: è¦è§£å‹ç¼©çš„ 7z æ–‡ä»¶è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ 7z æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    try:
        with py7zr.SevenZipFile(seven_zip_file, mode="r") as seven_zip_file:
            seven_zip_file.extractall(destination)
    except py7zr.Bad7zFile:
        raise ValueError(f"{seven_zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ 7z æ–‡ä»¶")
    except py7zr.Large7zFile:
        raise ValueError(f"{seven_zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except py7zr.PasswordRequired:
        raise ValueError(f"{seven_zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")


def unzip_folder(folder_path: str | Path):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œè§£å‹ç¼©æ‰€æœ‰æ”¯æŒçš„å‹ç¼©æ–‡ä»¶ã€‚æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬ zip å’Œ rarã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """

    def rename_unzip(file_path: Path) -> Path:
        name = file_path.stem
        suffix = file_path.suffix.lstrip(".")
        new_name = f"{name}({suffix})_unzip"
        return file_path.with_name(new_name)

    rules = {
        ".zip": (unzip_zip_file, rename_unzip, {}),
        ".rar": (unzip_rar_file, rename_unzip, {}), 
        ".tar": (unzip_tar_file, rename_unzip, {}), 
        ".7z": (unzip_7z_file, rename_unzip, {})
    }

    return handle_folder_files(folder_path, rules, progress_desc="Unziping folder")


def delete_file_or_folder(path: Path) -> None:
    """
    åˆ é™¤æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ã€‚

    :param path: æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    if path.is_file():
        path.unlink()
    elif path.is_dir():
        shutil.rmtree(path)


def copy_file_or_folder(source: Path, target: Path) -> None:
    """
    å¤åˆ¶æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ã€‚

    :param source: æºæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :param target: ç›®æ ‡æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    if source.is_file():
        shutil.copy2(source, target)
    elif source.is_dir():
        shutil.copytree(source, target, dirs_exist_ok=True)


def get_file_size(file_path: Path) -> HumanBytes:
    """
    è·å–æ–‡ä»¶å¤§å°ã€‚

    :param file_path: æ–‡ä»¶è·¯å¾„ã€‚
    :return: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ã€‚
    """
    return HumanBytes(file_path.stat().st_size)


def get_folder_size(folder_path: Path | str) -> HumanBytes:
    """
    è®¡ç®—æ–‡ä»¶å¤¹çš„å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•ï¼Œå¹¶è®¡ç®—å®ƒä»¬çš„å¤§å°æ€»å’Œã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :return: æ–‡ä»¶å¤¹çš„æ€»å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚
    """
    total_size = 0
    folder = Path(folder_path)
    for file in folder.rglob("*"):  # rglob('*') éå†æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•
        if file.is_file():
            total_size += file.stat().st_size  # è·å–æ–‡ä»¶å¤§å°
    return HumanBytes(total_size)


def get_file_hash(file_path: Path, chunk_size: int = 65536) -> str:
    """
    è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚

    :param file_path: æ–‡ä»¶è·¯å¾„ã€‚
    :param chunk_size: è¯»å–æ–‡ä»¶å—çš„å¤§å°ã€‚
    :return: æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚
    """
    hash_algo = hashlib.sha256()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(chunk_size), b""):
            hash_algo.update(chunk)
    return hash_algo.hexdigest()


def detect_identical_files(
    folder_list: List[Path], execution_mode: str = "thread"
) -> Dict[Tuple[str, int], List[Path]]:
    """
    æ£€æµ‹æ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨ç›¸åŒå†…å®¹çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ååæ·»åŠ æ–‡ä»¶å¤§å°ã€‚

    :param folder_list: æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨ã€‚
    :return: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶å¤§å°å’Œå“ˆå¸Œå€¼ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    scan_size_manager = ScanSizeManager(
        get_file_size,
        execution_mode,
        enable_result_cache=True,
        progress_desc="Scanning file size",
        show_progress=True,
    )
    scan_hash_manager = ScanHashManager(
        get_file_hash,
        execution_mode,
        enable_result_cache=True,
        progress_desc="Calculating file hashes",
        show_progress=True,
    )

    # æ ¹æ®æ–‡ä»¶å¤§å°è¿›è¡Œåˆæ­¥ç­›é€‰
    file_path_iter = (
        path
        for folder_path in folder_list
        for path in Path(folder_path).rglob("*")
        if path.is_file()
    )
    scan_size_manager.start(file_path_iter)
    file_size_iter = scan_size_manager.process_result_dict()

    # å¯¹äºç›¸åŒå¤§å°çš„æ–‡ä»¶ï¼Œè¿›ä¸€æ­¥è®¡ç®—å“ˆå¸Œå€¼, æ‰¾å‡ºå“ˆå¸Œå€¼ç›¸åŒçš„æ–‡ä»¶
    scan_hash_manager.start(file_size_iter)
    identical_dict = scan_hash_manager.process_result_dict()

    return identical_dict


def duplicate_files_report(identical_dict: Dict[Tuple[str, HumanBytes], List[Path]]):
    """
    ç”Ÿæˆä¸€ä¸ªè¯¦ç»†æŠ¥å‘Šï¼Œåˆ—å‡ºæ‰€æœ‰é‡å¤çš„æ–‡ä»¶åŠå…¶ä½ç½®ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    """
    if not identical_dict:
        print("\nNo identical files found.")
        return

    report = []
    total_size = HumanBytes(0)
    total_file_num = 0
    max_file_num = 0
    index = 0
    sort_identical_dict = dict(
        sorted(
            identical_dict.items(),
            key=lambda item: item[0][1] * len(item[1]),
            reverse=True,
        )
    )

    report.append("\nIdentical files found:\n")
    for (hash_value, file_size), file_list in sort_identical_dict.items():
        file_num = len(file_list)
        total_size += file_size * file_num
        total_file_num += file_num

        if file_num > max_file_num:
            max_file_num = file_num
            max_file_key = (hash_value, file_size)

        files_size = file_size * file_num
        data = [(str(file), file_size) for file in file_list]
        table_text = format_table(data, column_names=["File", "Size"])

        report.append(f"{index}.Hash: {hash_value} (Size: {files_size})")
        report.append(table_text + "\n")
        index += 1

    hash_value, file_size = max_file_key
    report.append(
        f"Total size of duplicate files: {total_size}"
    )
    report.append(
        f"Total number of duplicate files: {total_file_num}"
    )
    report.append(
        f"File with the most duplicates: {hash_value}(hash) {file_size}(size) {max_file_num}(number)"
    )

    print("\n".join(report))


def delete_identical_files(identical_dict: Dict[Tuple[str, int], List[Path]]):
    """
    åˆ é™¤æ–‡ä»¶å¤¹ä¸­ç›¸åŒå†…å®¹çš„æ–‡ä»¶ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :return: åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """

    def delete_and_return_size(path: Path, size: int):
        path.unlink()
        return size

    delete_list = []
    for (hash_value, file_size), file_list in identical_dict.items():
        delete_list.extend([(file_path, file_size) for file_path in file_list])

    delete_return_size_manager = DeleteReturnSizeManager(
        delete_and_return_size, 
        unpack_task_args=True,
        enable_result_cache=True
    )
    delete_return_size_manager.start(delete_list)
    delete_size = delete_return_size_manager.process_result_dict()

    print(f"\nTotal size of deleted files: {delete_size}")


def move_identical_files(
    identical_dict: Dict[Tuple[str, int], List[Path]],
    target_folder: str | Path,
    size_threshold: int = None,
):
    """
    å°†ç›¸åŒå†…å®¹çš„æ–‡ä»¶ç§»åŠ¨åˆ°æŒ‡å®šçš„ç›®æ ‡æ–‡ä»¶å¤¹ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :param target_folder: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :param size_threshold: æ–‡ä»¶å¤§å°é˜ˆå€¼ï¼Œåªæœ‰å¤§äºæ­¤é˜ˆå€¼çš„æ–‡ä»¶ä¼šè¢«ç§»åŠ¨ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä¸é™åˆ¶æ–‡ä»¶å¤§å°ã€‚
    :return: ç§»åŠ¨çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    target_folder = Path(target_folder)
    moved_files = {}
    report = []

    for (hash_value, file_size), file_list in tqdm(identical_dict.items()):
        target_subfolder = target_folder / f"{hash_value}({file_size})"
        if not target_subfolder.exists():
            target_subfolder.mkdir(parents=True)

        moved_files[hash_value] = []

        for file in file_list:
            if size_threshold is not None and file_size <= size_threshold:
                continue
            target_path = target_subfolder / file.name

            # å¦‚æœæ–‡ä»¶å·²ç»åœ¨ç›®æ ‡è·¯å¾„ï¼Œè·³è¿‡
            if file.resolve() == target_path.resolve():
                report.append(f"File {file} is already in the target path.")
                continue

            # ä»…ä¿ç•™ä¸€ä¸ªç›¸åŒåç§°çš„æ–‡ä»¶
            if target_path.exists():
                report.append(f"File {target_path} already exists. Skipping {file}.")
                file.unlink()  # åˆ é™¤é‡å¤æ–‡ä»¶
                continue

            try:
                file.rename(target_path)
                moved_files[hash_value].append((file, target_path))
                report.append(f"Moved: {file} -> {target_path}")
            except Exception as e:
                report.append(f"Error moving {file} to {target_path}: {e}")

    print("\n".join(report))

    return moved_files


def folder_to_file_path(
    folder_path: Path, file_extension: str, parent_dir: Path = None
) -> Path:
    """
    å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„ã€‚
    ä¾‹å¦‚ï¼Œç»™å®šæ–‡ä»¶å¤¹è·¯å¾„ '/home/user/folder1' å’Œæ–‡ä»¶æ‰©å±•å 'txt'ï¼Œå‡½æ•°ä¼šè¿”å›æ–‡ä»¶è·¯å¾„ '/home/user/folder1.txt'ã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :param file_extension: æ–‡ä»¶æ‰©å±•åã€‚
    :param parent_dir: æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•ã€‚
    :return: ä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„ã€‚
    """
    folder_path = Path(folder_path)
    if folder_path.is_file():
        raise ValueError("The provided path is a file, not a folder.")

    # è·å–æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•å’Œæ–‡ä»¶å¤¹åç§°
    folder_path = Path(folder_path)
    folder_name = folder_path.name  # è·å–æ–‡ä»¶å¤¹åç§°ï¼Œä¸å¸¦è·¯å¾„
    parent_dir = parent_dir or folder_path.parent  # è·å–æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•è·¯å¾„

    # ç”Ÿæˆä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„
    file_name = f"{folder_name}.{file_extension}"
    file_path = parent_dir / file_name

    return file_path


def replace_filenames(folder_path: Path | str, pattern: str, replacement: str):
    """
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ–‡ä»¶åä¸­çš„åŒ¹é…éƒ¨åˆ†ã€‚
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå°†å…¶ä¸­æ¯ä¸ªæ–‡ä»¶çš„æ–‡ä»¶åä¸­çš„åŒ¹é…å†…å®¹æ›¿æ¢ä¸º `replacement`ã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :param pattern: ç”¨äºåŒ¹é…æ–‡ä»¶åçš„æ­£åˆ™è¡¨è¾¾å¼ã€‚
    :param replacement: æ›¿æ¢åçš„æ–°å†…å®¹ã€‚
    """
    folder_path = Path(folder_path)  # å°†ä¼ å…¥çš„è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡
    file_path_list = [
        file_path for file_path in folder_path.glob("**/*") if file_path.is_file()
    ]  # ä½¿ç”¨glob('**/*')éå†ç›®å½•ä¸­çš„æ–‡ä»¶å’Œå­ç›®å½•

    for file in tqdm(file_path_list, desc="Replacing filenames"):
        new_filename = re.sub(pattern, replacement, file.name)
        if new_filename == file.name:
            continue

        new_file_path = file.with_name(new_filename)  # ä½¿ç”¨with_nameæ–¹æ³•ç”Ÿæˆæ–°æ–‡ä»¶è·¯å¾„
        if new_file_path.exists():
            continue

        file.rename(new_file_path)  # é‡å‘½åæ–‡ä»¶


def sort_by_number(file_path: Path, special_keywords: dict) -> tuple:
    """
    æ–‡ä»¶æ’åºè§„åˆ™ï¼š
    1. æŒ‰çˆ¶ç›®å½•è·¯å¾„è¿›è¡Œåˆ†ç»„ï¼ˆä¿è¯åŒç›®å½•ä¸‹çš„æ–‡ä»¶æ’åœ¨ä¸€èµ·ï¼‰
    2. å†æŒ‰å…³é”®å­—ä¼˜å…ˆçº§
    3. æœ€åæŒ‰æ–‡ä»¶åä¸­çš„æ•°å­—
    """
    file_name = file_path.name
    dir_key = file_path.parent.as_posix()   # ç”¨å­—ç¬¦ä¸²ï¼Œé¿å…æ··å…¥ int

    # å…³é”®å­—ä¼˜å…ˆçº§ï¼ˆè¶Šå°è¶Šé å‰ï¼‰
    keyword_priority = min(
        (
            special_keywords[keyword]
            for keyword in special_keywords
            if keyword in file_name
        ),
        default=0,
    )

    # æ•°å­—æå–
    matches = re.findall(r"\d+", file_name)
    numbers = [int(num) for num in matches] if matches else [float("inf")]

    return (dir_key, keyword_priority, *numbers)


def move_files_with_keyword(source_folder: Path | str, target_folder: Path | str, keyword: str = None):
    """
    å°† source_folder ä¸­æ‰€æœ‰æ–‡ä»¶ååŒ…å« keyword çš„æ–‡ä»¶ç§»åŠ¨åˆ° target_folderã€‚

    :param source_folder: æºæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆstr æˆ– Pathï¼‰
    :param target_folder: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆstr æˆ– Pathï¼‰
    :param keyword: éœ€è¦åŒ¹é…çš„å…³é”®è¯ï¼ˆstrï¼‰
    """
    source = Path(source_folder).resolve()
    target = Path(target_folder).resolve()
    keyword = keyword or ""

    # æºè·¯å¾„æ£€æŸ¥
    if not source.exists() or not source.is_dir():
        raise ValueError(f"æºç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶å¤¹: {source}")

    # ç¡®ä¿ç›®æ ‡è·¯å¾„å­˜åœ¨
    target.mkdir(parents=True, exist_ok=True)

    count_moved = 0
    count_skipped = 0

    for file in source.rglob("*"):
        if file.is_file() and (keyword in file.name):
            target_path = target / file.name  # âœ… ä¸è¦ä¿®æ”¹ target æœ¬èº«
            if target_path == file:
                print(f"âš ï¸ è·³è¿‡è‡ªèº«ç§»åŠ¨: {file}")
                count_skipped += 1
                continue
            elif target_path.exists():
                print(f"âš ï¸ è·³è¿‡åŒåæ–‡ä»¶: {target_path.name}")
                count_skipped += 1
                continue
            try:
                shutil.move(str(file), str(target_path))
                print(f"âœ… ç§»åŠ¨: {file} -> {target_path}")
                count_moved += 1
            except Exception as e:
                print(f"âŒ ç§»åŠ¨å¤±è´¥ {file}: {e}")

    print(f"\nğŸ“¦ å®Œæˆï¼šç§»åŠ¨ {count_moved} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {count_skipped} ä¸ªåŒåæ–‡ä»¶ã€‚")


def extract_folder_numbers(folder_path: Path | str) -> set:
    """
    éå†ç»™å®šæ–‡ä»¶å¤¹ï¼Œæå–æ‰€æœ‰æ–‡ä»¶å¤¹åç§°ä¸­åŒ¹é…*(\d+)çš„æ•°å­—éƒ¨åˆ†ï¼Œè¿”å›å­—å…¸ {æ–‡ä»¶å¤¹å: æ•°å­—(str)}ã€‚

    :param folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆstr æˆ– Pathï¼‰
    :return: å­—å…¸ï¼ŒåŒ…å«æ–‡ä»¶å¤¹åç§°å’Œå¯¹åº”çš„æ•°å­—éƒ¨åˆ†ã€‚
    """
    num_set = set()
    pattern = re.compile("\((\d+)\)")
    
    path = Path(folder_path)
    path_list = list(path.iterdir())
    for item in tqdm(path_list, desc="extract_folder_numbers"):
        if item.is_dir():
            match = pattern.search(item.name)
            if match:
                num_set.add(match.group(1))
    
    return num_set


def extract_file_numbers(folder_path: Path | str, suffix: str) -> set:
    """
    éå†ç»™å®šæ–‡ä»¶å¤¹ï¼Œæå–æ‰€æœ‰æ–‡ä»¶åä¸­åŒ¹é…*(\d+)çš„æ•°å­—éƒ¨åˆ†ï¼Œè¿”å›å­—å…¸ {æ–‡ä»¶å¤¹å: æ•°å­—(str)}ã€‚

    :param folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆstr æˆ– Pathï¼‰
    :param suffix: æ–‡ä»¶åç¼€å
    :return: å­—å…¸ï¼ŒåŒ…å«æ–‡ä»¶å¤¹åç§°å’Œå¯¹åº”çš„æ•°å­—éƒ¨åˆ†ã€‚
    """
    num_set = set()
    pattern = re.compile("\((\d+)\)")
    
    path = Path(folder_path)
    path_list = list(path.iterdir())
    for item in tqdm(path_list, desc="extract_txt_numbers"):
        if item.is_file() and item.suffix == suffix:
            match = pattern.search(item.name)
            if match:
                num_set.add(match.group(1))
    
    return num_set


def find_pure_folders(root: str | Path, only_nonempty: bool = False) -> list[Path]:
    """
    æŸ¥æ‰¾æŒ‡å®šè·¯å¾„ä¸‹æ‰€æœ‰çš„â€œçº¯ç²¹æ–‡ä»¶å¤¹â€ï¼Œå³åªåŒ…å«æ–‡ä»¶è€Œä¸åŒ…å«å­æ–‡ä»¶å¤¹çš„æ–‡ä»¶å¤¹ã€‚

    :param root: æ ¹ç›®å½•è·¯å¾„
    :param only_nonempty: æ˜¯å¦åªè¿”å›è‡³å°‘åŒ…å«ä¸€ä¸ªæ–‡ä»¶çš„çº¯ç²¹æ–‡ä»¶å¤¹
    :return: çº¯ç²¹æ–‡ä»¶å¤¹çš„ Path åˆ—è¡¨
    """
    root = Path(root)
    pure_folders = []

    for folder in root.rglob("*"):
        if folder.is_dir():
            subdirs = [p for p in folder.iterdir() if p.is_dir()]
            if not subdirs:  # æ²¡æœ‰å­æ–‡ä»¶å¤¹
                files = [p for p in folder.iterdir() if p.is_file()]
                if only_nonempty:
                    if files:
                        pure_folders.append(folder)
                else:
                    pure_folders.append(folder)

    return pure_folders


def align_width(s: str, max_len: int) -> str:
    """
    å°†å­—ç¬¦ä¸² s å·¦å¯¹é½åˆ°æœ€å¤§é•¿åº¦ max_lenï¼Œå¦‚æœéœ€è¦åˆ™æ·»åŠ ç©ºæ ¼ã€‚

    :param s: è¾“å…¥å­—ç¬¦ä¸²
    :param max_len: æœ€å¤§é•¿åº¦
    :return: å·¦å¯¹é½åçš„å­—ç¬¦ä¸²
    """
    adjust = wcswidth(s) - len(s)
    width = max(max_len - adjust, 0)  # ç¡®ä¿éè´Ÿ
    return f"{s:<{width}}"


def append_hash_to_filename(file_path: Path) -> str:
    """
    åœ¨æ–‡ä»¶åä¸­æ·»åŠ å“ˆå¸Œå€¼æ ‡è¯†

    :param file_path: æ–‡ä»¶è·¯å¾„
    :return: æ–°æ–‡ä»¶å
    """
    hash_value = get_file_hash(file_path)
    name, ext = file_path.stem, file_path.suffix
    new_file_path = file_path.with_name(f"{name}({hash_value}){ext}")
    file_path.rename(new_file_path)
    return new_file_path.name