import shutil
import logging
import hashlib
import zipfile, rarfile, py7zr
from pathlib import Path
from tqdm import tqdm
from typing import Callable, Dict, Tuple, List
from collections import defaultdict


def create_folder(path: str | Path) -> Path:
    """
    åˆ¤æ–­ç³»ç»Ÿæ˜¯å¦å­˜åœ¨è¯¥è·¯å¾„,æ²¡æœ‰åˆ™åˆ›å»ºã€‚

    :param path: è¦åˆ›å»ºçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: åˆ›å»ºæˆ–å­˜åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    path = Path(path)  # å°†è¾“å…¥è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡

    while True:
        try:
            if not path.exists():
                path.mkdir(parents=True)  # åˆ›å»ºç›®å½•,åŒ…æ‹¬ä»»ä½•å¿…è¦çš„çˆ¶ç›®å½•
            break
        except FileNotFoundError as e:
            print(e, path)
            path = path.parent  # ç§»é™¤æœ€åä¸€ä¸ªè·¯å¾„ç»„ä»¶
            continue

    return path

def get_all_file_paths(folder_path: str | Path) -> list:
    """
    è·å–ç»™å®šç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ã€‚
    
    :param directory: è¦éå†çš„ç›®å½•è·¯å¾„ã€‚
    :return: æ‰€æœ‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„åˆ—è¡¨ã€‚
    """
    folder_path = Path(folder_path)
    file_paths = []  # å­˜å‚¨æ–‡ä»¶è·¯å¾„çš„åˆ—è¡¨

    # éå†æ–‡ä»¶å¤¹
    for file_path in list(folder_path.glob('**/*')):
        if not file_path.is_file():
            continue
        file_paths.append(file_path)

    return file_paths

def handle_folder(folder_path: str | Path, rules: Dict[str, Tuple[Callable[[Path, Path], None], Callable[[Path], Path]]]) -> List[Tuple[Path, Exception]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    ä¸å±äºæŒ‡å®šåç¼€çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚å¤„ç†åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚
    å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param rules: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åç¼€ï¼Œå€¼ä¸ºå¤„ç†è¯¥ç±»å‹æ–‡ä»¶çš„å‡½æ•°å’Œé‡å‘½åå‡½æ•°çš„å…ƒç»„ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    def handle_file(source: Path, destination: Path, action: Callable[[Path, Path], None]):
        """
        å¤„ç†æ–‡ä»¶ï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨åˆ™æ‰§è¡ŒæŒ‡å®šçš„æ“ä½œã€‚
        
        :param source: æºæ–‡ä»¶è·¯å¾„ã€‚
        :param destination: ç›®æ ‡æ–‡ä»¶è·¯å¾„ã€‚
        :param action: å¤„ç†æ–‡ä»¶çš„å‡½æ•°æˆ–æ–¹æ³•ã€‚
        """
        if destination.exists():
            return
        
        destination.parent.mkdir(parents=True, exist_ok=True)
        action(source, destination)

    folder_path = Path(folder_path)
    new_folder_path = folder_path.parent / (folder_path.name + "_re")
    error_list = []

    # éå†æ–‡ä»¶å¤¹
    for file_path in tqdm(list(folder_path.glob('**/*'))):
        if not file_path.is_file():
            continue

        rel_path = file_path.relative_to(folder_path)
        new_file_path = new_folder_path / rel_path
        file_suffix = file_path.suffix.lower()[1:]
        try:
            action, rename_func = rules.get(file_suffix, (shutil.copy, lambda x: x))
            final_path = rename_func(new_file_path)
            handle_file(file_path, final_path, action)
        except Exception as e:
            error_list.append((file_path, e))
            try:
                shutil.copy(file_path, new_file_path)
            except Exception as e:
                error_list.append((file_path, e))

    return error_list

def compress_folder(folder_path: str | Path) -> List[Tuple[Path, Exception]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå‹ç¼©å¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬å›¾ç‰‡ã€è§†é¢‘å’ŒPDFã€‚ä¸å±äºè¿™ä¸‰ç§ç±»å‹çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚
    å‹ç¼©åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    def rename_mp4(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        parent = file_path.parent
        return parent / Path(name + '_compressed.mp4')
    
    def rename_pdf(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        parent = file_path.parent
        return parent / Path(name + '_compressed.pdf')

    from tools.ImageProcessing import compress_img
    from tools.VideoProcessing import compress_video, gif_to_video
    from tools.DocumentConversion import compress_pdf
    from constants import IMG_SUFFIXES, VIDEO_SUFFIXES

    rules = {suffix: (compress_img, lambda x: x) for suffix in IMG_SUFFIXES}
    rules.update({suffix: (compress_video,rename_mp4) for suffix in VIDEO_SUFFIXES})
    rules.update({suffix: (gif_to_video, rename_mp4) for suffix in ['gif', 'GIF']})
    rules.update({suffix: (compress_pdf,rename_pdf) for suffix in ['pdf', 'PDF']})

    return handle_folder(folder_path, rules)

def unzip_zip_file(zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ zip æ–‡ä»¶ã€‚
    
    :param zip_file: è¦è§£å‹ç¼©çš„ zip æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with zipfile.ZipFile(zip_file) as zip_file:
            zip_file.extractall(destination)
        # logging.info(f"{zip_file} è§£å‹ç¼©æˆåŠŸ")
    except zipfile.BadZipFile:
        raise ValueError(f"{zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ zip æ–‡ä»¶")
    except zipfile.LargeZipFile:
        raise ValueError(f"{zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except RuntimeError:
        raise ValueError("{zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_rar_file(rar_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ rar æ–‡ä»¶ã€‚
    
    :param rar_file: è¦è§£å‹ç¼©çš„ rar æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with rarfile.RarFile(rar_file) as rar_file:
            rar_file.extractall(destination)
        # logging.info(f"{rar_file} è§£å‹ç¼©æˆåŠŸ")
    except rarfile.BadRarFile:
        raise ValueError(f"{rar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ rar æ–‡ä»¶")
    except rarfile.LargeRarFile:
        raise ValueError(f"{rar_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except rarfile.PasswordRequired:
        raise ValueError(f"{rar_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_7z_file(seven_zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ 7z æ–‡ä»¶ã€‚
    
    :param seven_zip_file: è¦è§£å‹ç¼©çš„ 7z æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with py7zr.SevenZipFile(seven_zip_file, mode='r') as seven_zip_file:
            seven_zip_file.extractall(destination)
        # logging.info(f"{seven_zip_file} è§£å‹ç¼©æˆåŠŸ")
    except py7zr.Bad7zFile:
        raise ValueError(f"{seven_zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ 7z æ–‡ä»¶")
    except py7zr.Large7zFile:
        raise ValueError(f"{seven_zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except py7zr.PasswordRequired:
        raise ValueError(f"{seven_zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")
    
def unzip_folder(folder_path: str | Path):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œè§£å‹ç¼©æ‰€æœ‰æ”¯æŒçš„å‹ç¼©æ–‡ä»¶ã€‚æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬ zip å’Œ rarã€‚
    
    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    def rename_unzip(file_path: Path) -> Path:
        name = file_path.stem
        parent = file_path.parent
        return parent / Path(name + '_unzip')
    
    rules = {'zip': (unzip_zip_file, rename_unzip)}
    rules.update({'rar': (unzip_rar_file, rename_unzip)})
    rules.update({'7z': (unzip_7z_file, rename_unzip)})

    return handle_folder(folder_path, rules)

def delete_files(file_path: str | Path):
    """
    åˆ é™¤æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹ã€‚
    
    :param file_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    file_path = Path(file_path)
    logging.info(f'å¼€å§‹åˆ é™¤:{file_path}')
    
    for file in tqdm(list(file_path.iterdir())):
        if file.is_file():
            file.unlink()
        elif file.is_dir():
            shutil.rmtree(file)
            
    logging.info(f'åˆ é™¤å®Œæˆ:{file_path}')

def print_directory_structure(folder_path: str='.', indent: str='', exclude_dirs: list=None, exclude_exts: list=None, max_depth: int=3):
    """
    æ‰“å°æŒ‡å®šæ–‡ä»¶å¤¹çš„ç›®å½•ç»“æ„ã€‚
    
    :param folder_path: èµ·å§‹æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚
    :param indent: ç¼©è¿›å­—ç¬¦ä¸²ï¼Œç”¨äºæ ¼å¼åŒ–è¾“å‡ºã€‚
    :param exclude_dirs: è¦æ’é™¤çš„ç›®å½•åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    :param exclude_exts: è¦æ’é™¤çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    :param max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼Œé»˜è®¤ä¸º3ã€‚
    """
    from constants import FILE_ICONS
    folder_path: Path = Path(folder_path)
    if exclude_dirs is None:
        exclude_dirs = []
    if exclude_exts is None:
        exclude_exts = []
    if max_depth < 1:
        return
    if not any(folder_path.iterdir()):
        return

    # è®¡ç®—æ–‡ä»¶åçš„æœ€å¤§é•¿åº¦ï¼Œå¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œè®¾ç½®é»˜è®¤é•¿åº¦
    files = [item for item in folder_path.iterdir() if item.is_file()]
    max_name_len = max((len(str(item.name)) for item in files), default=0)
    
    for item in folder_path.iterdir():
        # æ’é™¤æŒ‡å®šçš„ç›®å½•
        if item.is_dir() and item.name in exclude_dirs:
            continue
        
        # æ’é™¤æŒ‡å®šçš„æ–‡ä»¶ç±»å‹
        if item.is_file() and any(item.suffix == ext for ext in exclude_exts):
            continue
        
        if item.is_dir():
            print(f"{indent}ğŸ“ {item.name}/")
            print_directory_structure(item, indent + '    ', exclude_dirs, exclude_exts, max_depth-1)
        else:
            icon = FILE_ICONS.get(item.suffix, FILE_ICONS['default'])
            print(f"{indent}{icon} {item.name:<{max_name_len}} \t({item.stat().st_size} bytes)")

def file_hash(file_path: Path) -> str:
    """
    è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚

    :param file_path: æ–‡ä»¶è·¯å¾„ã€‚
    :return: æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚
    """
    hash_algo = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_algo.update(chunk)
    return hash_algo.hexdigest()

def detect_identical_files(folder_path: str | Path) -> Dict[Tuple[str, int], List[Path]]:
    """
    æ£€æµ‹æ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨ç›¸åŒå†…å®¹çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ååæ·»åŠ æ–‡ä»¶å¤§å°ã€‚

    :param folder_path: è¦æ£€æµ‹çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶å¤§å°å’Œå“ˆå¸Œå€¼ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    folder_path = Path(folder_path)
    
    # æ ¹æ®æ–‡ä»¶å¤§å°è¿›è¡Œåˆæ­¥ç­›é€‰
    size_dict = defaultdict(list)
    for file_path in tqdm(list(folder_path.glob('**/*')), desc='Scanning files'):
        if not file_path.is_file():
            continue
        file_size = file_path.stat().st_size
        size_dict[file_size].append(file_path)
    
    # å¯¹äºç›¸åŒå¤§å°çš„æ–‡ä»¶ï¼Œè¿›ä¸€æ­¥è®¡ç®—å“ˆå¸Œå€¼
    hash_dict = defaultdict(list)
    for size, files in tqdm(size_dict.items(), desc='Calculating file hashes'):
        if len(files) < 2:
            continue
        for file_path in files:
            file_hash_value = file_hash(file_path)
            hash_dict[(file_hash_value, size)].append(file_path)
    
    # æ‰¾å‡ºå“ˆå¸Œå€¼ç›¸åŒçš„æ–‡ä»¶
    identical_files = {k: v for k, v in hash_dict.items() if len(v) > 1}
    
    return identical_files

def duplicate_files_report(identical_files: Dict[Tuple[str, int], List[Path]]):
    """
    ç”Ÿæˆä¸€ä¸ªè¯¦ç»†æŠ¥å‘Šï¼Œåˆ—å‡ºæ‰€æœ‰é‡å¤çš„æ–‡ä»¶åŠå…¶ä½ç½®ã€‚

    :param identical_files: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    """
    report = []
    if identical_files:
        report.append("Identical files found:")
        for (hash_value,file_size), file_list in identical_files.items():
            report.append(f"Hash: {hash_value}")
            max_name_len = max(len(str(file)) for file in file_list)
            for file in file_list:
                report.append(f" - {str(file):<{max_name_len}} (Size: {file_size} bytes)")
    else:
        report.append("No identical files found.")
        
    print("\n".join(report))

def delete_identical_files(identical_files: Dict[Tuple[str, int], List[Path]]):
    """
    åˆ é™¤æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰ç›¸åŒå†…å®¹çš„æ–‡ä»¶ã€‚

    :param identical_files: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :return: åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    delete_list = []
    for (hash_value,file_size), file_list in identical_files.items():
        for file in file_list:
            try:
                file.unlink()
                delete_list.append(file)
                print(f"Deleted: {file}")
            except Exception as e:
                print(f"Error deleting {file}: {e}")

    return delete_list

def move_identical_files(identical_files: Dict[Tuple[str, int], List[Path]], target_folder: str | Path, size_threshold: int = None):
    """
    å°†ç›¸åŒå†…å®¹çš„æ–‡ä»¶ç§»åŠ¨åˆ°æŒ‡å®šçš„ç›®æ ‡æ–‡ä»¶å¤¹ã€‚

    :param identical_files: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :param target_folder: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :param size_threshold: æ–‡ä»¶å¤§å°é˜ˆå€¼ï¼Œåªæœ‰å¤§äºæ­¤é˜ˆå€¼çš„æ–‡ä»¶ä¼šè¢«ç§»åŠ¨ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä¸é™åˆ¶æ–‡ä»¶å¤§å°ã€‚
    :return: ç§»åŠ¨çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    target_folder = Path(target_folder)
    moved_files = []
    report = []

    for (hash_value, file_size), file_list in tqdm(identical_files.items()):
        for file in file_list:
            if size_threshold is not None and file_size <= size_threshold:
                continue
            target_subfolder = target_folder / hash_value
            if not target_subfolder.exists():
                target_subfolder.mkdir(parents=True)
            target_path = target_subfolder / file.name

            # å¦‚æœæ–‡ä»¶å·²ç»åœ¨ç›®æ ‡è·¯å¾„ï¼Œè·³è¿‡
            if file.resolve() == target_path.resolve():
                report.append(f"File {file} is already in the target path.")
                continue
            
            # ä»…ä¿ç•™ä¸€ä¸ªç›¸åŒåç§°çš„æ–‡ä»¶
            if target_path.exists():
                report.append(f"File {target_path} already exists. Skipping {file}.")
                file.unlink()  # åˆ é™¤é‡å¤æ–‡ä»¶
                continue

            try:
                file.rename(target_path)
                moved_files.append((file, target_path))
                report.append(f"Moved: {file} -> {target_path}")
            except Exception as e:
                report.append(f"Error moving {file} to {target_path}: {e}")
    
    print("\n".join(report))

    return moved_files