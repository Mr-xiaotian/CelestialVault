import shutil
import logging
import hashlib
import zipfile, rarfile, py7zr
from pathlib import Path
from tqdm import tqdm
from typing import Callable
from collections import defaultdict


def create_folder(path: str | Path) -> Path:
    """
    åˆ¤æ–­ç³»ç»Ÿæ˜¯å¦å­˜åœ¨è¯¥è·¯å¾„,æ²¡æœ‰åˆ™åˆ›å»ºã€‚

    :param path: è¦åˆ›å»ºçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: åˆ›å»ºæˆ–å­˜åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    path = Path(path)  # å°†è¾“å…¥è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡

    while True:
        try:
            if not path.exists():
                path.mkdir(parents=True)  # åˆ›å»ºç›®å½•,åŒ…æ‹¬ä»»ä½•å¿…è¦çš„çˆ¶ç›®å½•
            break
        except FileNotFoundError as e:
            print(e, path)
            path = path.parent  # ç§»é™¤æœ€åä¸€ä¸ªè·¯å¾„ç»„ä»¶
            continue

    return path

def get_all_file_paths(folder_path: str | Path) -> list:
    """
    è·å–ç»™å®šç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ã€‚
    
    :param directory: è¦éå†çš„ç›®å½•è·¯å¾„ã€‚
    :return: æ‰€æœ‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„åˆ—è¡¨ã€‚
    """
    folder_path = Path(folder_path)
    file_paths = []  # å­˜å‚¨æ–‡ä»¶è·¯å¾„çš„åˆ—è¡¨

    # éå†æ–‡ä»¶å¤¹
    for file_path in list(folder_path.glob('**/*')):
        if not file_path.is_file():
            continue
        file_paths.append(file_path)

    return file_paths

def handle_file(source: Path, destination: Path, action: Callable[[Path, Path], None]):
    """
    å¤„ç†æ–‡ä»¶ï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨åˆ™æ‰§è¡ŒæŒ‡å®šçš„æ“ä½œã€‚
    
    :param source: æºæ–‡ä»¶è·¯å¾„ã€‚
    :param destination: ç›®æ ‡æ–‡ä»¶è·¯å¾„ã€‚
    :param action: å¤„ç†æ–‡ä»¶çš„å‡½æ•°æˆ–æ–¹æ³•ã€‚
    """
    destination.parent.mkdir(parents=True, exist_ok=True)
    if not destination.exists():
        action(source, destination)
    else:
        logging.warning(f"File {destination} already exists. Skipping...")

def compress_folder(folder_path: str | Path) -> list:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå‹ç¼©å¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬å›¾ç‰‡ã€è§†é¢‘å’ŒPDFã€‚ä¸å±äºè¿™ä¸‰ç§ç±»å‹çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚
    å‹ç¼©åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    from .ImageProcessing import compress_img
    from .VideoProcessing import compress_video
    from .DocumentConversion import compress_pdf
    from constants import IMG_SUFFIXES, VIDEO_SUFFIXES

    folder_path = Path(folder_path)
    new_folder_path = folder_path.parent / (folder_path.name + "_re")
    error_list = []

    # éå†æ–‡ä»¶å¤¹
    for file_path in tqdm(list(folder_path.glob('**/*'))):
        if not file_path.is_file():
            continue

        rel_path = file_path.relative_to(folder_path)
        new_file_path = new_folder_path / rel_path
        file_suffix = file_path.suffix.lower()[1:]
        try:
            if file_suffix in IMG_SUFFIXES:
                handle_file(file_path, new_file_path, compress_img)
            elif file_suffix in VIDEO_SUFFIXES:
                name = new_file_path.stem.replace("_compressed", "")
                parent = new_file_path.parent
                new_video_path = parent / Path(name + '_compressed.mp4')
                handle_file(file_path, new_video_path, compress_video)
            elif file_suffix == 'pdf':
                name = new_file_path.stem.replace("_compressed", "")
                parent = new_file_path.parent
                new_pdf_path = parent / Path(name + '_compressed.pdf')
                handle_file(file_path, new_pdf_path, compress_pdf)
            else:
                handle_file(file_path, new_file_path, shutil.copy)
        except OSError as e:
            error_list.append((file_path, e))
            try:
                shutil.copy(file_path, new_file_path)
            except OSError as e:
                error_list.append((file_path, e))

    return error_list

def unzip_zip_file(zip_file: Path) -> bool:
    """
    è§£å‹ç¼©æŒ‡å®šçš„ zip æ–‡ä»¶ã€‚
    
    :param zip_file: è¦è§£å‹ç¼©çš„ zip æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with zipfile.ZipFile(zip_file) as zip_file:
            zip_file.extractall(zip_file.parent)
        logging.info(f"{zip_file} è§£å‹ç¼©æˆåŠŸ")
        return True
    except zipfile.BadZipFile:
        logging.error(f"{zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ zip æ–‡ä»¶")
    except zipfile.LargeZipFile:
        logging.error(f"{zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except RuntimeError:
        logging.error("{zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")
    return False

def unzip_rar_file(rar_file: Path) -> bool:
    """
    è§£å‹ç¼©æŒ‡å®šçš„ rar æ–‡ä»¶ã€‚
    
    :param rar_file: è¦è§£å‹ç¼©çš„ rar æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with rarfile.RarFile(rar_file) as rar_file:
            rar_file.extractall(rar_file.parent)
        logging.info(f"{rar_file} è§£å‹ç¼©æˆåŠŸ")
        return True
    except rarfile.BadRarFile:
        logging.error(f"{rar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ rar æ–‡ä»¶")
    except rarfile.LargeRarFile:
        logging.error(f"{rar_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except rarfile.PasswordRequired:
        logging.error(f"{rar_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")
    return False

def unzip_7z_file(seven_zip_file: Path) -> bool:
    """
    è§£å‹ç¼©æŒ‡å®šçš„ 7z æ–‡ä»¶ã€‚
    
    :param seven_zip_file: è¦è§£å‹ç¼©çš„ 7z æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with py7zr.SevenZipFile(seven_zip_file, mode='r') as seven_zip_file:
            seven_zip_file.extractall(seven_zip_file.parent)
        logging.info(f"{seven_zip_file} è§£å‹ç¼©æˆåŠŸ")
        return True
    except py7zr.Bad7zFile:
        logging.error(f"{seven_zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ 7z æ–‡ä»¶")
    except py7zr.Large7zFile:
        logging.error(f"{seven_zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except py7zr.PasswordRequired:
        logging.error(f"{seven_zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")
    return False
    
def unzip_files(folder_path: str | Path):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œè§£å‹ç¼©æ‰€æœ‰æ”¯æŒçš„å‹ç¼©æ–‡ä»¶ã€‚æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬ zip å’Œ rarã€‚
    
    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    folder_path = Path(folder_path)
    logging.info(f'å¼€å§‹è§£å‹:{folder_path}')
    successful_list = []
    unsuccessful_list = []

    # éå†æ–‡ä»¶å¤¹
    for file_path in tqdm(list(folder_path.glob('**/*'))):
        if not file_path.is_file():
            continue

        file_suffix = file_path.suffix.lower()[1:]

        if file_suffix == 'zip':
            if unzip_zip_file(file_path):
                successful_list.append(file_path)
            else:
                unsuccessful_list.append(file_path)
        elif file_suffix == 'rar':
            if unzip_rar_file(file_path):
                successful_list.append(file_path)
            else:
                unsuccessful_list.append(file_path)
        elif file_suffix == '7z':
            if unzip_7z_file(file_path):
                successful_list.append(file_path)
            else:
                unsuccessful_list.append(file_path)
            
    logging.info(f'è§£å‹å®Œæˆ:{folder_path}')
    logging.info(f'æˆåŠŸè§£å‹æ–‡ä»¶: {successful_list}')
    logging.info(f'è§£å‹å¤±è´¥æ–‡ä»¶: {unsuccessful_list}')
    
    return successful_list, unsuccessful_list

def delete_files(file_path: str | Path):
    """
    åˆ é™¤æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹ã€‚
    
    :param file_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    file_path = Path(file_path)
    logging.info(f'å¼€å§‹åˆ é™¤:{file_path}')
    
    for file in tqdm(list(file_path.glob('**/*'))):
        if file.is_file():
            file.unlink()
        elif file.is_dir():
            shutil.rmtree(file)
            
    logging.info(f'åˆ é™¤å®Œæˆ:{file_path}')

def print_directory_structure(start_path: str='.', indent: str='', exclude_dirs: list=None, exclude_exts: list=None, max_depth: int=3):
    """
    æ‰“å°æŒ‡å®šæ–‡ä»¶å¤¹çš„ç›®å½•ç»“æ„ã€‚
    
    :param start_path: èµ·å§‹æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚
    :param indent: ç¼©è¿›å­—ç¬¦ä¸²ï¼Œç”¨äºæ ¼å¼åŒ–è¾“å‡ºã€‚
    :param exclude_dirs: è¦æ’é™¤çš„ç›®å½•åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    :param exclude_exts: è¦æ’é™¤çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    """
    from constants import FILE_ICONS
    if exclude_dirs is None:
        exclude_dirs = []
    if exclude_exts is None:
        exclude_exts = []
    if max_depth < 1:
        return

    start_path: Path = Path(start_path)
    
    for item in start_path.iterdir():
        # æ’é™¤æŒ‡å®šçš„ç›®å½•
        if item.is_dir() and item.name in exclude_dirs:
            continue
        
        # æ’é™¤æŒ‡å®šçš„æ–‡ä»¶ç±»å‹
        if item.is_file() and any(item.suffix == ext for ext in exclude_exts):
            continue
        
        if item.is_dir():
            print(f"{indent}ğŸ“ {item.name}/")
            print_directory_structure(item, indent + '    ', exclude_dirs, exclude_exts, max_depth-1)
        else:
            icon = FILE_ICONS.get(item.suffix, FILE_ICONS['default'])
            print(f"{indent}{icon} {item.name}")

def file_hash(file_path: Path) -> str:
    """
    è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚

    :param file_path: æ–‡ä»¶è·¯å¾„ã€‚
    :return: æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚
    """
    hash_algo = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_algo.update(chunk)
    return hash_algo.hexdigest()

def detect_identical_files(folder_path: str | Path):
    """
    æ£€æµ‹æ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨ç›¸åŒå†…å®¹çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ååæ·»åŠ æ–‡ä»¶å¤§å°ã€‚

    :param folder_path: è¦æ£€æµ‹çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    folder_path = Path(folder_path)
    
    # æ ¹æ®æ–‡ä»¶å¤§å°è¿›è¡Œåˆæ­¥ç­›é€‰
    size_dict = defaultdict(list)
    for file_path in tqdm(list(folder_path.glob('**/*'))):
        if not file_path.is_file():
            continue
        file_size = file_path.stat().st_size
        size_dict[file_size].append(file_path)
    
    # å¯¹äºç›¸åŒå¤§å°çš„æ–‡ä»¶ï¼Œè¿›ä¸€æ­¥è®¡ç®—å“ˆå¸Œå€¼
    hash_dict = defaultdict(list)
    for size, files in tqdm(size_dict.items()):
        if len(files) < 2:
            continue
        for file_path in files:
            file_hash_value = file_hash(file_path)
            file_path_str = str(file_path)
            hash_dict[(file_hash_value, size)].append(file_path_str)
    
    # æ‰¾å‡ºå“ˆå¸Œå€¼ç›¸åŒçš„æ–‡ä»¶
    identical_files = {k: v for k, v in hash_dict.items() if len(v) > 1}
    
    if identical_files:
        print("Identical files found:")
        for (hash_value,file_size), file_list in identical_files.items():
            print(f"Hash: {hash_value}")
            max_name_len = max(len(file) for file in file_list)
            for file in file_list:
                print(f" - {file:<{max_name_len}} (Size: {file_size} bytes)")
    else:
        print("No identical files found.")

def delete_identical_files(folder_path: str | Path, delete_size: int, delete_hash: str):
    """
    åˆ é™¤æ–‡ä»¶å¤¹ä¸­ç›¸åŒå†…å®¹çš„æ–‡ä»¶ã€‚

    :param folder_path: è¦åˆ é™¤çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :param delete_size: è¦åˆ é™¤çš„æ–‡ä»¶å¤§å°ã€‚
    :param delete_hash: è¦åˆ é™¤çš„æ–‡ä»¶å“ˆå¸Œå€¼ã€‚
    """
    folder_path = Path(folder_path)
    
    delete_list = []
    for file_path in tqdm(list(folder_path.glob('**/*'))):
        if not file_path.is_file():
            continue
        if file_path.stat().st_size != delete_size:
            continue
        if file_hash(file_path) != delete_hash:
            continue
        file_path.unlink()
        delete_list.append(file_path)

    return delete_list
