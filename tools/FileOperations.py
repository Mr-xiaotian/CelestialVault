import shutil, re
import logging
import hashlib
import zipfile, rarfile, tarfile, py7zr
from pathlib import Path
from tqdm import tqdm
from typing import Callable, Tuple, Dict, List
from collections import defaultdict
from instances.inst_task import TaskManager, ExampleTaskManager

class HandleFileManager(TaskManager):
    def __init__(self, func, folder_path: Path, new_folder_path: Path, rules: Dict[str, Tuple[Callable, Callable]], 
                 execution_mode='serial', worker_limit=50, max_retries=3, max_info=50, progress_desc="Processing", show_progress=False):
        super().__init__(func, execution_mode, worker_limit, max_retries, max_info, progress_desc, show_progress)
        self.folder_path = folder_path
        self.new_folder_path = new_folder_path
        self.rules = rules

    def get_args(self, file_path: Path):
        rel_path = file_path.relative_to(self.folder_path)
        new_file_path = self.new_folder_path / rel_path

        file_suffix = file_path.suffix.lower().lstrip('.')
        action_func, rename_func = self.rules.get(file_suffix, (shutil.copy, lambda x: x))

        final_path = rename_func(new_file_path)
        return (file_path, final_path, action_func)
    
    def process_result(self, file_path: Path, result):
        return
    
    def handle_error_dict(self):
        error_path_dict = defaultdict(list)

        for file_path, error in self.get_error_dict().items():
            rel_path = file_path.relative_to(self.folder_path)
            new_file_path = self.new_folder_path / rel_path
            shutil.copy(file_path, new_file_path)
            error_path_dict[(type(error).__name__, str(error))].append(new_file_path)
        return error_path_dict
    

class DetectIdenticalManager(TaskManager):
    def get_args(self, task):
        return (task[0], )
    
    def process_result(self, task: Path, result):
        return result
    
    def process_result_dict(self):
        result_path_dict = defaultdict(list)

        for (path, size), hash_vault in self.get_result_dict().items():
            result_path_dict[(hash_vault, size)].append(path)
        return result_path_dict
    

class ScanFileManager(ExampleTaskManager):
    def process_result_dict(self):
        size_dict = defaultdict(list)

        for path, size in self.get_result_dict().items():
            size_dict[size].append(path)
        return size_dict


def create_folder(path: str | Path) -> Path:
    """
    åˆ¤æ–­ç³»ç»Ÿæ˜¯å¦å­˜åœ¨è¯¥è·¯å¾„,æ²¡æœ‰åˆ™åˆ›å»ºã€‚

    :param path: è¦åˆ›å»ºçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: åˆ›å»ºæˆ–å­˜åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    path = Path(path)  # å°†è¾“å…¥è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡

    while True:
        try:
            if not path.exists():
                path.mkdir(parents=True)  # åˆ›å»ºç›®å½•,åŒ…æ‹¬ä»»ä½•å¿…è¦çš„çˆ¶ç›®å½•
            break
        except FileNotFoundError as e:
            print(e, path)
            path = path.parent  # ç§»é™¤æœ€åä¸€ä¸ªè·¯å¾„ç»„ä»¶
            continue

    return path

def handle_file(source: Path, destination: Path, action: Callable[[Path, Path], None]):
    """
    å¤„ç†æ–‡ä»¶ï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨åˆ™æ‰§è¡ŒæŒ‡å®šçš„æ“ä½œã€‚
    
    :param source: æºæ–‡ä»¶è·¯å¾„ã€‚
    :param destination: ç›®æ ‡æ–‡ä»¶è·¯å¾„ã€‚
    :param action: å¤„ç†æ–‡ä»¶çš„å‡½æ•°æˆ–æ–¹æ³•ã€‚
    """
    if destination.exists():
        return
    
    # åˆ¤æ–­ destination æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
    if destination.suffix:
        destination.parent.mkdir(parents=True, exist_ok=True)
    else:
        destination.mkdir(parents=True, exist_ok=True)
    action(source, destination)

def handle_folder(folder_path: str | Path, rules: Dict[str, Tuple[Callable[[Path, Path], None], Callable[[Path], Path]]], 
                  execution_mode: str = 'serial', progress_desc: str = "Processing files") -> Dict[Exception, List[Path]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    ä¸å±äºæŒ‡å®šåç¼€çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚å¤„ç†åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚
    å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param rules: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åç¼€ï¼Œå€¼ä¸ºå¤„ç†è¯¥ç±»å‹æ–‡ä»¶çš„å‡½æ•°å’Œé‡å‘½åå‡½æ•°çš„å…ƒç»„ã€‚
    :param execution_mode: æ‰§è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 'serial' æˆ– 'thread' 'process'ã€‚é»˜è®¤ä¸º 'serial'ã€‚
    :param progress_desc: è¿›åº¦æ¡æè¿°ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    folder_path = Path(folder_path)
    new_folder_path = folder_path.parent / (folder_path.name + "_re")

    handlefile_manager = HandleFileManager(handle_file, folder_path, new_folder_path, rules,
                                           execution_mode=execution_mode, worker_limit=6, 
                                           progress_desc=progress_desc, show_progress=True)

    file_path_list = [file_path for file_path in folder_path.glob('**/*') if file_path.is_file()]
    handlefile_manager.start(file_path_list)

    error_path_dict = handlefile_manager.handle_error_dict()
    return error_path_dict

def compress_folder(folder_path: str | Path, execution_mode: str = 'thread') -> List[Tuple[Path, Exception]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå‹ç¼©å¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬å›¾ç‰‡ã€è§†é¢‘å’ŒPDFã€‚ä¸å±äºè¿™ä¸‰ç§ç±»å‹çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚
    å‹ç¼©åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param execution_mode: æ‰§è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 'serial' æˆ– 'thread' 'process'ã€‚é»˜è®¤ä¸º 'thread'ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    def rename_mp4(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        suffix = file_path.suffix.lstrip('.')
        new_name = f"{name}({suffix})_compressed.mp4"
        return file_path.with_name(new_name)
    
    def rename_pdf(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        new_name = f"{name}_compressed.pdf"
        return file_path.with_name(new_name)

    from tools.ImageProcessing import compress_img
    from tools.VideoProcessing import compress_video
    from tools.DocumentConversion import compress_pdf
    from constants import IMG_SUFFIXES, VIDEO_SUFFIXES

    rules = {suffix: (compress_img, lambda x: x) for suffix in IMG_SUFFIXES}
    rules.update({suffix: (compress_video,rename_mp4) for suffix in VIDEO_SUFFIXES})
    rules.update({suffix: (compress_pdf,rename_pdf) for suffix in ['pdf', 'PDF']})

    return handle_folder(folder_path, rules, execution_mode, progress_desc='Compressing folder')

def unzip_zip_file(zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ zip æ–‡ä»¶ã€‚
    
    :param zip_file: è¦è§£å‹ç¼©çš„ zip æ–‡ä»¶è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ zip æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    try:
        with zipfile.ZipFile(zip_file) as zip_file:
            zip_file.extractall(destination)
    except zipfile.BadZipFile:
        raise ValueError(f"{zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ zip æ–‡ä»¶")
    except zipfile.LargeZipFile:
        raise ValueError(f"{zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except RuntimeError:
        raise ValueError("{zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_rar_file(rar_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ rar æ–‡ä»¶ã€‚
    
    :param rar_file: è¦è§£å‹ç¼©çš„ rar æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with rarfile.RarFile(rar_file) as rar_file:
            rar_file.extractall(destination)
    except rarfile.BadRarFile:
        raise ValueError(f"{rar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ rar æ–‡ä»¶")
    except rarfile.LargeRarFile:
        raise ValueError(f"{rar_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except rarfile.PasswordRequired:
        raise ValueError(f"{rar_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_tar_file(tar_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ tar æ–‡ä»¶ã€‚
    
    :param tar_file: è¦è§£å‹ç¼©çš„ tar æ–‡ä»¶è·¯å¾„ã€‚
    :param destination: è§£å‹ç¼©çš„ç›®æ ‡è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ tar æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ tar æ–‡ä»¶
    if not tarfile.is_tarfile(tar_file):
        raise ValueError(f"{tar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ tar æ–‡ä»¶")
    try:
        # æ‰“å¼€ tar æ–‡ä»¶
        with tarfile.open(tar_file) as tar:
            # æå–æ‰€æœ‰å†…å®¹åˆ°ç›®æ ‡è·¯å¾„
            tar.extractall(path=destination)
    except tarfile.ReadError:
        raise ValueError(f"{tar_file} è¯»å–é”™è¯¯ï¼Œå¯èƒ½ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ tar æ–‡ä»¶")
    except Exception as e:
        raise ValueError(f"è§£å‹ {tar_file} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

def unzip_7z_file(seven_zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ 7z æ–‡ä»¶ã€‚
    
    :param seven_zip_file: è¦è§£å‹ç¼©çš„ 7z æ–‡ä»¶è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ 7z æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    try:
        with py7zr.SevenZipFile(seven_zip_file, mode='r') as seven_zip_file:
            seven_zip_file.extractall(destination)
    except py7zr.Bad7zFile:
        raise ValueError(f"{seven_zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ 7z æ–‡ä»¶")
    except py7zr.Large7zFile:
        raise ValueError(f"{seven_zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except py7zr.PasswordRequired:
        raise ValueError(f"{seven_zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_folder(folder_path: str | Path):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œè§£å‹ç¼©æ‰€æœ‰æ”¯æŒçš„å‹ç¼©æ–‡ä»¶ã€‚æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬ zip å’Œ rarã€‚
    
    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    def rename_unzip(file_path: Path) -> Path:
        name = file_path.stem
        suffix = file_path.suffix.lstrip('.')
        new_name = f"{name}({suffix})_unzip"
        return file_path.with_name(new_name)
    
    rules = {'zip': (unzip_zip_file, rename_unzip)}
    rules.update({'rar': (unzip_rar_file, rename_unzip)})
    rules.update({'tar': (unzip_tar_file, rename_unzip)})
    rules.update({'7z': (unzip_7z_file, rename_unzip)})

    return handle_folder(folder_path, rules, progress_desc="Unziping folder")

def delete_files(file_path: str | Path):
    """
    åˆ é™¤æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹ã€‚
    
    :param file_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    file_path = Path(file_path)
    logging.info(f'å¼€å§‹åˆ é™¤:{file_path}')
    
    for file in tqdm(list(file_path.iterdir())):
        if file.is_file():
            file.unlink()
        elif file.is_dir():
            shutil.rmtree(file)
            
    logging.info(f'åˆ é™¤å®Œæˆ:{file_path}')

def print_directory_structure(folder_path: str='.', indent: str='', exclude_dirs: list=None, exclude_exts: list=None, max_depth: int=3):
    """
    æ‰“å°æŒ‡å®šæ–‡ä»¶å¤¹çš„ç›®å½•ç»“æ„ã€‚
    
    :param folder_path: èµ·å§‹æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚
    :param indent: ç¼©è¿›å­—ç¬¦ä¸²ï¼Œç”¨äºæ ¼å¼åŒ–è¾“å‡ºã€‚
    :param exclude_dirs: è¦æ’é™¤çš„ç›®å½•åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    :param exclude_exts: è¦æ’é™¤çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    :param max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼Œé»˜è®¤ä¸º3ã€‚
    """
    from constants import FILE_ICONS
    folder_path: Path = Path(folder_path)
    if exclude_dirs is None:
        exclude_dirs = []
    if exclude_exts is None:
        exclude_exts = []
    if max_depth < 1:
        return
    if not any(folder_path.iterdir()):
        return

    # è®¡ç®—æ–‡ä»¶åçš„æœ€å¤§é•¿åº¦ï¼Œå¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œè®¾ç½®é»˜è®¤é•¿åº¦
    files = [item for item in folder_path.iterdir() if item.is_file()]
    max_name_len = max((len(str(item.name)) for item in files), default=0)
    
    for item in folder_path.iterdir():
        # æ’é™¤æŒ‡å®šçš„ç›®å½•
        if item.is_dir() and item.name in exclude_dirs:
            continue
        
        # æ’é™¤æŒ‡å®šçš„æ–‡ä»¶ç±»å‹
        if item.is_file() and any(item.suffix == ext for ext in exclude_exts):
            continue
        
        if item.is_dir():
            print(f"{indent}ğŸ“ {item.name}/")
            print_directory_structure(item, indent + '    ', exclude_dirs, exclude_exts, max_depth-1)
        else:
            icon = FILE_ICONS.get(item.suffix, FILE_ICONS['default'])
            print(f"{indent}{icon} {item.name:<{max_name_len}} \t({item.stat().st_size} bytes)")

def get_file_hash(file_path: Path) -> str:
    """
    è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚

    :param file_path: æ–‡ä»¶è·¯å¾„ã€‚
    :return: æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚
    """
    hash_algo = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_algo.update(chunk)
    return hash_algo.hexdigest()

def detect_identical_files(folder_path: str | Path, execution_mode: str ='thread') -> Dict[Tuple[str, int], List[Path]]:
    """
    æ£€æµ‹æ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨ç›¸åŒå†…å®¹çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ååæ·»åŠ æ–‡ä»¶å¤§å°ã€‚

    :param folder_path: è¦æ£€æµ‹çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶å¤§å°å’Œå“ˆå¸Œå€¼ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    folder_path = Path(folder_path)
    
    # æ ¹æ®æ–‡ä»¶å¤§å°è¿›è¡Œåˆæ­¥ç­›é€‰
    scan_file_manager = ScanFileManager(lambda x: x.stat().st_size, execution_mode, 
                                        progress_desc='Scanning files', show_progress=True)

    file_path_list = [path for path in folder_path.rglob('*') if path.is_file()]
    scan_file_manager.start(file_path_list)

    size_dict = scan_file_manager.process_result_dict()
    size_dict = {k: v for k, v in size_dict.items() if len(v) > 1}
    
    # å¯¹äºç›¸åŒå¤§å°çš„æ–‡ä»¶ï¼Œè¿›ä¸€æ­¥è®¡ç®—å“ˆå¸Œå€¼
    detect_identical_manager = DetectIdenticalManager(get_file_hash, execution_mode, 
                                                      progress_desc='Calculating file hashes', show_progress=True)

    file_task_list = [(file_path, size) for size, files in size_dict.items() for file_path in files]
    detect_identical_manager.start(file_task_list)

    # æ‰¾å‡ºå“ˆå¸Œå€¼ç›¸åŒçš„æ–‡ä»¶
    hash_dict = detect_identical_manager.process_result_dict()
    identical_dict = {k: v for k, v in hash_dict.items() if len(v) > 1}
    
    return identical_dict

def duplicate_files_report(identical_dict: Dict[Tuple[str, int], List[Path]]):
    """
    ç”Ÿæˆä¸€ä¸ªè¯¦ç»†æŠ¥å‘Šï¼Œåˆ—å‡ºæ‰€æœ‰é‡å¤çš„æ–‡ä»¶åŠå…¶ä½ç½®ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    """
    from tools.Utilities import bytes_to_human_readable
    if not identical_dict:
        print("\nNo identical files found.")
        return 

    report = []
    total_size = 0
    total_file_num = 0
    max_file_num = 0
    sort_identical_dict = dict(sorted(identical_dict.items(), key=lambda item: item[0][1], reverse=True))
    report.append("\nIdentical files found:\n")
    for (hash_value,file_size), file_list in sort_identical_dict.items():
        report.append(f"Hash: {hash_value} (Size: {file_size} bytes)")

        file_num = len(file_list)
        total_size += file_size * file_num
        total_file_num += file_num

        if file_num > max_file_num:
            max_file_num = file_num
            max_file_key = (hash_value,file_size)

        max_name_len = max(len(str(file)) for file in file_list)
        readable_size = bytes_to_human_readable(file_size)
        for file in file_list:
            report.append(f" - {str(file):<{max_name_len}} (Size: {readable_size})")

    report.append(f"\n\nTotal size of duplicate files: {bytes_to_human_readable(total_size)}")
    report.append(f"Total number of duplicate files: {total_file_num}")
    report.append(f"File with the most duplicates: {max_file_key}")
        
    print("\n".join(report))

def delete_identical_files(identical_dict: Dict[Tuple[str, int], List[Path]]):
    """
    åˆ é™¤æ–‡ä»¶å¤¹ä¸­ç›¸åŒå†…å®¹çš„æ–‡ä»¶ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :return: åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    from tools.Utilities import bytes_to_human_readable
    report = []
    delete_size = 0
    for (hash_value,file_size), file_list in identical_dict.items():
        for file in tqdm(file_list, desc='Deleting files'):
            try:
                file.unlink()
                delete_size += file_size
                report.append(f"Deleted: {file}")
            except Exception as e:
                report.append(f"Error deleting {file}: {e}")

    report.append(f"\nTotal size of deleted files: {bytes_to_human_readable(delete_size)}")
    print("\n".join(report))

def move_identical_files(identical_dict: Dict[Tuple[str, int], List[Path]], target_folder: str | Path, size_threshold: int = None):
    """
    å°†ç›¸åŒå†…å®¹çš„æ–‡ä»¶ç§»åŠ¨åˆ°æŒ‡å®šçš„ç›®æ ‡æ–‡ä»¶å¤¹ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :param target_folder: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :param size_threshold: æ–‡ä»¶å¤§å°é˜ˆå€¼ï¼Œåªæœ‰å¤§äºæ­¤é˜ˆå€¼çš„æ–‡ä»¶ä¼šè¢«ç§»åŠ¨ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä¸é™åˆ¶æ–‡ä»¶å¤§å°ã€‚
    :return: ç§»åŠ¨çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    target_folder = Path(target_folder)
    moved_files = []
    report = []

    for (hash_value, file_size), file_list in tqdm(identical_dict.items()):
        for file in file_list:
            if size_threshold is not None and file_size <= size_threshold:
                continue
            target_subfolder = target_folder / hash_value
            if not target_subfolder.exists():
                target_subfolder.mkdir(parents=True)
            target_path = target_subfolder / file.name

            # å¦‚æœæ–‡ä»¶å·²ç»åœ¨ç›®æ ‡è·¯å¾„ï¼Œè·³è¿‡
            if file.resolve() == target_path.resolve():
                report.append(f"File {file} is already in the target path.")
                continue
            
            # ä»…ä¿ç•™ä¸€ä¸ªç›¸åŒåç§°çš„æ–‡ä»¶
            if target_path.exists():
                report.append(f"File {target_path} already exists. Skipping {file}.")
                file.unlink()  # åˆ é™¤é‡å¤æ–‡ä»¶
                continue

            try:
                file.rename(target_path)
                moved_files.append((file, target_path))
                report.append(f"Moved: {file} -> {target_path}")
            except Exception as e:
                report.append(f"Error moving {file} to {target_path}: {e}")
    
    print("\n".join(report))

    return moved_files

def folder_to_file_path(folder_path: Path, file_extension: str) -> Path:
    """
    å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„ã€‚
    ä¾‹å¦‚ï¼Œç»™å®šæ–‡ä»¶å¤¹è·¯å¾„ '/home/user/folder1' å’Œæ–‡ä»¶æ‰©å±•å 'txt'ï¼Œå‡½æ•°ä¼šè¿”å›æ–‡ä»¶è·¯å¾„ '/home/user/folder1.txt'ã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :param file_extension: æ–‡ä»¶æ‰©å±•åã€‚
    :return: ä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„ã€‚
    """
    # è·å–æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•å’Œæ–‡ä»¶å¤¹åç§°
    folder_name = folder_path.stem  # è·å–æ–‡ä»¶å¤¹åç§°ï¼Œä¸å¸¦è·¯å¾„
    parent_dir = folder_path.parent  # è·å–æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•è·¯å¾„
    
    # ç”Ÿæˆä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„
    file_name = f"{folder_name}.{file_extension}"
    file_path = parent_dir / file_name
    
    return file_path

def replace_filenames(folder_path: Path | str, pattern: str, replacement: str):
    """
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ–‡ä»¶åä¸­çš„åŒ¹é…éƒ¨åˆ†ã€‚
    
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå°†å…¶ä¸­æ¯ä¸ªæ–‡ä»¶çš„æ–‡ä»¶åä¸­çš„åŒ¹é…å†…å®¹æ›¿æ¢ä¸º `replacement`ã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :param pattern: ç”¨äºåŒ¹é…æ–‡ä»¶åçš„æ­£åˆ™è¡¨è¾¾å¼ã€‚
    :param replacement: æ›¿æ¢åçš„æ–°å†…å®¹ã€‚
    """
    folder_path = Path(folder_path)  # å°†ä¼ å…¥çš„è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡
    for file in folder_path.glob('**/*'):  # ä½¿ç”¨glob('**/*')éå†ç›®å½•ä¸­çš„æ–‡ä»¶å’Œå­ç›®å½•
        if not file.is_file():  # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
            continue
        
        new_filename = re.sub(pattern, replacement, file.name)
        if new_filename == file.name:
            continue
        
        new_file_path = file.with_name(new_filename)  # ä½¿ç”¨with_nameæ–¹æ³•ç”Ÿæˆæ–°æ–‡ä»¶è·¯å¾„
        file.rename(new_file_path)  # é‡å‘½åæ–‡ä»¶