import shutil, re, os
import logging
import hashlib
import zipfile, rarfile, tarfile, py7zr
from pathlib import Path
from tqdm import tqdm
from typing import Callable, Tuple, Dict, List
from collections import defaultdict
from constants import FILE_ICONS
from instances.inst_task import TaskManager, ExampleTaskManager
from tools.Utilities import bytes_to_human_readable

class HandleFileManager(TaskManager):
    def __init__(self, func, folder_path: Path, new_folder_path: Path, rules: Dict[str, Tuple[Callable, Callable]], 
                 execution_mode='serial', worker_limit=50, max_retries=3, max_info=50, progress_desc="Processing", show_progress=False):
        super().__init__(func, execution_mode, worker_limit, max_retries, max_info, progress_desc, show_progress)
        self.folder_path = folder_path
        self.new_folder_path = new_folder_path
        self.rules = rules

    def get_args(self, file_path: Path):
        rel_path = file_path.relative_to(self.folder_path)
        new_file_path = self.new_folder_path / rel_path

        file_suffix = file_path.suffix.lower()
        action_func, rename_func = self.rules.get(file_suffix, (shutil.copy, lambda x: x))

        final_path = rename_func(new_file_path)
        return (file_path, final_path, action_func)
    
    def process_result(self, file_path: Path, result):
        return
    
    def handle_error_dict(self):
        error_path_dict = defaultdict(list)

        for file_path, error in self.get_error_dict().items():
            rel_path = file_path.relative_to(self.folder_path)
            new_file_path = self.new_folder_path / rel_path
            shutil.copy(file_path, new_file_path)
            error_path_dict[(type(error).__name__, str(error))].append(new_file_path)
        return error_path_dict
    

class ScanFileManager(ExampleTaskManager):
    def process_result_dict(self):
        size_dict = defaultdict(list)

        for path, size in self.get_result_dict().items():
            size_dict[size].append(path)

        size_dict = {k: v for k, v in size_dict.items() if len(v) > 1}
        return size_dict
    

class DetectIdenticalManager(TaskManager):
    def get_args(self, task):
        return (task[0], )
    
    def process_result(self, task: Path, result):
        return result
    
    def process_result_dict(self):
        identical_dict = defaultdict(list)

        for (path, size), hash_value in self.get_result_dict().items():
            identical_dict[(hash_value, size)].append(path)

        identical_dict = {k: v for k, v in identical_dict.items() if len(v) > 1}
        return identical_dict


def create_folder(path: str | Path) -> Path:
    """
    åˆ¤æ–­ç³»ç»Ÿæ˜¯å¦å­˜åœ¨è¯¥è·¯å¾„,æ²¡æœ‰åˆ™åˆ›å»ºã€‚

    :param path: è¦åˆ›å»ºçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: åˆ›å»ºæˆ–å­˜åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    path = Path(path)  # å°†è¾“å…¥è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡

    while True:
        try:
            if not path.exists():
                path.mkdir(parents=True)  # åˆ›å»ºç›®å½•,åŒ…æ‹¬ä»»ä½•å¿…è¦çš„çˆ¶ç›®å½•
            break
        except FileNotFoundError as e:
            print(e, path)
            path = path.parent  # ç§»é™¤æœ€åä¸€ä¸ªè·¯å¾„ç»„ä»¶
            continue

    return path

def handle_file(source: Path, destination: Path, action: Callable[[Path, Path], None]):
    """
    å¤„ç†æ–‡ä»¶ï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨åˆ™æ‰§è¡ŒæŒ‡å®šçš„æ“ä½œã€‚
    
    :param source: æºæ–‡ä»¶è·¯å¾„ã€‚
    :param destination: ç›®æ ‡æ–‡ä»¶è·¯å¾„ã€‚
    :param action: å¤„ç†æ–‡ä»¶çš„å‡½æ•°æˆ–æ–¹æ³•ã€‚
    """
    if destination.exists():
        return
    
    # åˆ¤æ–­ destination æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
    if destination.suffix:
        destination.parent.mkdir(parents=True, exist_ok=True)
    else:
        destination.mkdir(parents=True, exist_ok=True)
    action(source, destination)

def handle_folder(folder_path: str | Path, rules: Dict[str, Tuple[Callable[[Path, Path], None], Callable[[Path], Path]]], 
                  execution_mode: str = 'serial', progress_desc: str = "Processing files") -> Dict[Exception, List[Path]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    ä¸å±äºæŒ‡å®šåç¼€çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚å¤„ç†åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚
    å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param rules: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åç¼€ï¼Œå€¼ä¸ºå¤„ç†è¯¥ç±»å‹æ–‡ä»¶çš„å‡½æ•°å’Œé‡å‘½åå‡½æ•°çš„å…ƒç»„ã€‚
    :param execution_mode: æ‰§è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 'serial' æˆ– 'thread' 'process'ã€‚é»˜è®¤ä¸º 'serial'ã€‚
    :param progress_desc: è¿›åº¦æ¡æè¿°ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    folder_path = Path(folder_path)
    new_folder_path = folder_path.parent / (folder_path.name + "_re")

    handlefile_manager = HandleFileManager(handle_file, folder_path, new_folder_path, rules,
                                           execution_mode=execution_mode, worker_limit=6, 
                                           progress_desc=progress_desc, show_progress=True)

    file_path_list = [file_path for file_path in folder_path.glob('**/*') if file_path.is_file()]
    handlefile_manager.start(file_path_list)

    error_path_dict = handlefile_manager.handle_error_dict()
    return error_path_dict

def compress_folder(folder_path: str | Path, execution_mode: str = 'thread') -> List[Tuple[Path, Exception]]:
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œæ ¹æ®æ–‡ä»¶åç¼€åå¯¹æ–‡ä»¶è¿›è¡Œå‹ç¼©å¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„æ–‡ä»¶å­˜å‚¨åˆ°æ–°çš„ç›®å½•ä¸­ã€‚
    æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬å›¾ç‰‡ã€è§†é¢‘å’ŒPDFã€‚ä¸å±äºè¿™ä¸‰ç§ç±»å‹çš„æ–‡ä»¶å°†è¢«ç›´æ¥å¤åˆ¶åˆ°æ–°ç›®å½•ä¸­ã€‚
    å‹ç¼©åçš„æ–‡ä»¶ä¼šä¿æŒåŸå§‹çš„ç›®å½•ç»“æ„ã€‚å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ä¼šè·³è¿‡å¤„ç†ã€‚å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°çš„ä»»ä½•é”™è¯¯éƒ½ä¼šè¢«è®°å½•å¹¶è¿”å›ã€‚

    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    :param execution_mode: æ‰§è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ˜¯ 'serial' æˆ– 'thread' 'process'ã€‚é»˜è®¤ä¸º 'thread'ã€‚
    :return: åŒ…å«å› é”™è¯¯æœªèƒ½æ­£ç¡®å¤„ç†çš„æ–‡ä»¶åŠå…¶å¯¹åº”é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨ã€‚æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œé”™è¯¯å¯¹è±¡ã€‚
    """
    def rename_mp4(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        suffix = file_path.suffix.lstrip('.')
        new_name = f"{name}({suffix})_compressed.mp4"
        return file_path.with_name(new_name)
    
    def rename_pdf(file_path: Path) -> Path:
        name = file_path.stem.replace("_compressed", "")
        new_name = f"{name}_compressed.pdf"
        return file_path.with_name(new_name)

    from tools.ImageProcessing import compress_img
    from tools.VideoProcessing import compress_video
    from tools.DocumentConversion import compress_pdf
    from constants import IMG_SUFFIXES, VIDEO_SUFFIXES

    rules = {suffix: (compress_img, lambda x: x) for suffix in IMG_SUFFIXES}
    rules.update({suffix: (compress_video,rename_mp4) for suffix in VIDEO_SUFFIXES})
    # rules.update({'.pdf': (compress_pdf,rename_pdf)})

    return handle_folder(folder_path, rules, execution_mode, progress_desc='Compressing folder')

def unzip_zip_file(zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ zip æ–‡ä»¶ã€‚
    
    :param zip_file: è¦è§£å‹ç¼©çš„ zip æ–‡ä»¶è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ zip æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    try:
        with zipfile.ZipFile(zip_file) as zip_file:
            zip_file.extractall(destination)
    except zipfile.BadZipFile:
        raise ValueError(f"{zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ zip æ–‡ä»¶")
    except zipfile.LargeZipFile:
        raise ValueError(f"{zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except RuntimeError:
        raise ValueError("{zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_rar_file(rar_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ rar æ–‡ä»¶ã€‚
    
    :param rar_file: è¦è§£å‹ç¼©çš„ rar æ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with rarfile.RarFile(rar_file) as rar_file:
            rar_file.extractall(destination)
    except rarfile.BadRarFile:
        raise ValueError(f"{rar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ rar æ–‡ä»¶")
    except rarfile.LargeRarFile:
        raise ValueError(f"{rar_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except rarfile.PasswordRequired:
        raise ValueError(f"{rar_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_tar_file(tar_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ tar æ–‡ä»¶ã€‚
    
    :param tar_file: è¦è§£å‹ç¼©çš„ tar æ–‡ä»¶è·¯å¾„ã€‚
    :param destination: è§£å‹ç¼©çš„ç›®æ ‡è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ tar æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ tar æ–‡ä»¶
    if not tarfile.is_tarfile(tar_file):
        raise ValueError(f"{tar_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ tar æ–‡ä»¶")
    try:
        # æ‰“å¼€ tar æ–‡ä»¶
        with tarfile.open(tar_file) as tar:
            # æå–æ‰€æœ‰å†…å®¹åˆ°ç›®æ ‡è·¯å¾„
            tar.extractall(path=destination)
    except tarfile.ReadError:
        raise ValueError(f"{tar_file} è¯»å–é”™è¯¯ï¼Œå¯èƒ½ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ tar æ–‡ä»¶")
    except Exception as e:
        raise ValueError(f"è§£å‹ {tar_file} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

def unzip_7z_file(seven_zip_file: Path, destination: Path):
    """
    è§£å‹ç¼©æŒ‡å®šçš„ 7z æ–‡ä»¶ã€‚
    
    :param seven_zip_file: è¦è§£å‹ç¼©çš„ 7z æ–‡ä»¶è·¯å¾„ã€‚
    :raises ValueError: å¦‚æœæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ 7z æ–‡ä»¶æˆ–å‘ç”Ÿå…¶ä»–é”™è¯¯ã€‚
    """
    try:
        with py7zr.SevenZipFile(seven_zip_file, mode='r') as seven_zip_file:
            seven_zip_file.extractall(destination)
    except py7zr.Bad7zFile:
        raise ValueError(f"{seven_zip_file} ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ 7z æ–‡ä»¶")
    except py7zr.Large7zFile:
        raise ValueError(f"{seven_zip_file} å¤ªå¤§äº†ï¼Œæ— æ³•è§£å‹ç¼©")
    except py7zr.PasswordRequired:
        raise ValueError(f"{seven_zip_file} å—å¯†ç ä¿æŠ¤ï¼Œæ— æ³•è§£å‹ç¼©")

def unzip_folder(folder_path: str | Path):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œè§£å‹ç¼©æ‰€æœ‰æ”¯æŒçš„å‹ç¼©æ–‡ä»¶ã€‚æ”¯æŒçš„æ–‡ä»¶ç±»å‹åŒ…æ‹¬ zip å’Œ rarã€‚
    
    :param folder_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    def rename_unzip(file_path: Path) -> Path:
        name = file_path.stem
        suffix = file_path.suffix.lstrip('.')
        new_name = f"{name}({suffix})_unzip"
        return file_path.with_name(new_name)
    
    rules = {'.zip': (unzip_zip_file, rename_unzip)}
    rules.update({'.rar': (unzip_rar_file, rename_unzip)})
    rules.update({'.tar': (unzip_tar_file, rename_unzip)})
    rules.update({'.7z': (unzip_7z_file, rename_unzip)})

    return handle_folder(folder_path, rules, progress_desc="Unziping folder")

def delete_files(file_path: str | Path):
    """
    åˆ é™¤æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹ã€‚
    
    :param file_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚
    """
    file_path = Path(file_path)
    logging.info(f'å¼€å§‹åˆ é™¤:{file_path}')
    
    for file in tqdm(list(file_path.iterdir())):
        if file.is_file():
            file.unlink()
        elif file.is_dir():
            shutil.rmtree(file)
            
    logging.info(f'åˆ é™¤å®Œæˆ:{file_path}')

def print_directory_structure(folder_path: str='.', indent: str='    ', exclude_dirs: list=None, exclude_exts: list=None, max_depth: int=3):
    """
    æ‰“å°æŒ‡å®šæ–‡ä»¶å¤¹çš„ç›®å½•ç»“æ„ã€‚
    
    :param folder_path: èµ·å§‹æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚
    :param indent: ç¼©è¿›å­—ç¬¦ä¸²ï¼Œç”¨äºæ ¼å¼åŒ–è¾“å‡ºã€‚
    :param exclude_dirs: è¦æ’é™¤çš„ç›®å½•åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    :param exclude_exts: è¦æ’é™¤çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨ã€‚
    :param max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼Œé»˜è®¤ä¸º3ã€‚
    """
    folder_path: Path = Path(folder_path)

    if exclude_dirs is None:
        exclude_dirs = []
    if exclude_exts is None:
        exclude_exts = []

    def get_structure_list(folder_path, indent, max_depth):
        if max_depth < 1:
            return [], 0
        if not any(folder_path.iterdir()):
            return [], 0

        # è®¡ç®—æ–‡ä»¶åçš„æœ€å¤§é•¿åº¦ï¼Œå¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œè®¾ç½®é»˜è®¤é•¿åº¦
        files = [item for item in folder_path.iterdir() if item.is_file()]
        max_name_len = max((len(str(item.name)) for item in files), default=0)

        folder_structure_list = []
        file_structure_list = []
        folder_size = 0
        
        for item in folder_path.iterdir():
            # æ’é™¤æŒ‡å®šçš„ç›®å½•
            if item.is_dir() and item.name in exclude_dirs:
                continue
            
            # æ’é™¤æŒ‡å®šçš„æ–‡ä»¶ç±»å‹
            if item.is_file() and any(item.suffix == ext for ext in exclude_exts):
                continue
            
            if item.is_dir():
                subfolder_structure_list, subfolder_size = get_structure_list(item, indent + '    ', max_depth-1)
                folder_size += subfolder_size
                reable_subfolder_size = bytes_to_human_readable(subfolder_size)

                folder_structure_list.append(f"{indent}ğŸ“ {item.name}/    ({reable_subfolder_size})")
                folder_structure_list.extend(subfolder_structure_list)
            else:
                icon = FILE_ICONS.get(item.suffix, FILE_ICONS['default'])
                file_size = item.stat().st_size
                folder_size += file_size
                reable_file_size = bytes_to_human_readable(file_size)

                file_structure_list.append(f"{indent}{icon} {item.name:<{max_name_len}}\t({reable_file_size})")

        structure_list = folder_structure_list + file_structure_list
        return structure_list, folder_size

    structure_list, folder_size = get_structure_list(folder_path, indent, max_depth)
    reable_folder_size = bytes_to_human_readable(folder_size)

    structure_list = [f"ğŸ“ {folder_path.name}/    ({reable_folder_size})"] + structure_list
    print('\n'.join(structure_list))

def compare_structure(dir1, dir2, indent=''):
    """
    æ¯”è¾ƒä¸¤ä¸ªæ–‡ä»¶å¤¹çš„ç»“æ„ï¼Œå¹¶æ‰“å°å‡ºä»…åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­å­˜åœ¨çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ã€‚
    
    :param dir1: ç¬¬ä¸€ä¸ªæ–‡ä»¶å¤¹è·¯å¾„
    :param dir2: ç¬¬äºŒä¸ªæ–‡ä»¶å¤¹è·¯å¾„
    :param indent: ç¼©è¿›å­—ç¬¦ä¸²ï¼Œç”¨äºæ ¼å¼åŒ–è¾“å‡º
    """
    dir1 = Path(dir1)
    dir2 = Path(dir2)
    dir1_name = str(dir1)
    dir2_name = str(dir2)

    # æ£€æŸ¥ç›®å½•æ˜¯å¦æœ‰æ•ˆ
    if not dir1.is_dir() or not dir2.is_dir():
        raise ValueError(f"è¾“å…¥è·¯å¾„å¿…é¡»æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶å¤¹: {dir1} æˆ– {dir2}")

    def get_structure_list(dir1, dir2, dir1_name, dir2_name, indent):
        # è·å–æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        dir1_files = set(os.listdir(dir1))
        dir2_files = set(os.listdir(dir2))
        only_in_dir1 = sorted(dir1_files - dir2_files)
        only_in_dir2 = sorted(dir2_files - dir1_files)
        common_files = sorted(dir1_files & dir2_files)

        print_folder_list = []
        print_file_list = []

        # æ‰“å°ä»…åœ¨ dir1 å’Œ dir2 ä¸­å­˜åœ¨çš„é¡¹ç›®
        for item in only_in_dir1 + only_in_dir2:
            item_path = dir1 / item if item in only_in_dir1 else dir2 / item
            location = dir1_name if item in only_in_dir1 else dir2_name

            if item_path.is_dir():
                print_folder_list.append(f"{indent}ğŸ“ [{location}] {item}")
            elif item_path.is_file():
                icon = FILE_ICONS.get(item_path.suffix, FILE_ICONS['default'])
                print_file_list.append(f"{indent}{icon} [{location}] {item}")

        # æ‰“å°å…±åŒé¡¹ç›®
        for item in common_files:
            item_path1, item_path2 = dir1 / item, dir2 / item

            # æ‰“å°æ–‡ä»¶å¤¹ä¸æ–‡ä»¶å¤¹çš„æ¯”è¾ƒç»“æœ
            if item_path1.is_dir() and item_path2.is_dir():
                subfolder_print_list = get_structure_list(item_path1, item_path2, dir1_name, dir2_name, indent + '    ')
                if subfolder_print_list:
                    print_folder_list.append(f"{indent}ğŸ“ {item}/")
                    print_folder_list.extend(subfolder_print_list)

            # æ‰“å°æ–‡ä»¶å¤¹ä¸æ–‡ä»¶çš„æ··åˆæƒ…å†µ
            elif (item_path1.is_file() and item_path2.is_dir()) or (item_path1.is_dir() and item_path2.is_file()):
                print_file_list.append(f"{indent}{item} (one is a file, the other is a folder)")

        return print_folder_list + print_file_list
    
    structure_list = get_structure_list(dir1, dir2, dir1_name, dir2_name, indent)
    print('\n'.join(structure_list))

def get_file_hash(file_path: Path) -> str:
    """
    è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚

    :param file_path: æ–‡ä»¶è·¯å¾„ã€‚
    :return: æ–‡ä»¶çš„å“ˆå¸Œå€¼ã€‚
    """
    hash_algo = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_algo.update(chunk)
    return hash_algo.hexdigest()

def detect_identical_files(folder_path: str | Path, execution_mode: str ='thread') -> Dict[Tuple[str, int], List[Path]]:
    """
    æ£€æµ‹æ–‡ä»¶å¤¹ä¸­æ˜¯å¦å­˜åœ¨ç›¸åŒå†…å®¹çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ååæ·»åŠ æ–‡ä»¶å¤§å°ã€‚

    :param folder_path: è¦æ£€æµ‹çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :return: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶å¤§å°å’Œå“ˆå¸Œå€¼ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    folder_path = Path(folder_path)
    
    scan_file_manager = ScanFileManager(lambda x: x.stat().st_size, execution_mode, 
                                        progress_desc='Scanning files', show_progress=True)
    detect_identical_manager = DetectIdenticalManager(get_file_hash, execution_mode, 
                                                      progress_desc='Calculating file hashes', show_progress=True)

    # æ ¹æ®æ–‡ä»¶å¤§å°è¿›è¡Œåˆæ­¥ç­›é€‰
    file_path_list = [path for path in folder_path.rglob('*') if path.is_file()]
    scan_file_manager.start(file_path_list)
    size_dict = scan_file_manager.process_result_dict()
    
    # å¯¹äºç›¸åŒå¤§å°çš„æ–‡ä»¶ï¼Œè¿›ä¸€æ­¥è®¡ç®—å“ˆå¸Œå€¼, æ‰¾å‡ºå“ˆå¸Œå€¼ç›¸åŒçš„æ–‡ä»¶
    file_task_list = [(file_path, size) for size, files in size_dict.items() for file_path in files]
    detect_identical_manager.start(file_task_list)
    identical_dict = detect_identical_manager.process_result_dict()
    
    return identical_dict

def duplicate_files_report(identical_dict: Dict[Tuple[str, int], List[Path]]):
    """
    ç”Ÿæˆä¸€ä¸ªè¯¦ç»†æŠ¥å‘Šï¼Œåˆ—å‡ºæ‰€æœ‰é‡å¤çš„æ–‡ä»¶åŠå…¶ä½ç½®ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    """
    if not identical_dict:
        print("\nNo identical files found.")
        return 

    report = []
    total_size = 0
    total_file_num = 0
    max_file_num = 0
    sort_identical_dict = dict(sorted(identical_dict.items(), key=lambda item: item[0][1], reverse=True))
    report.append("\nIdentical files found:\n")
    for (hash_value,file_size), file_list in sort_identical_dict.items():
        report.append(f"Hash: {hash_value} (Size: {file_size} bytes)")

        file_num = len(file_list)
        total_size += file_size * file_num
        total_file_num += file_num

        if file_num > max_file_num:
            max_file_num = file_num
            max_file_key = (hash_value, file_size, file_num)

        max_name_len = max(len(str(file)) for file in file_list)
        readable_size = bytes_to_human_readable(file_size)
        for file in file_list:
            report.append(f" - {str(file):<{max_name_len}} (Size: {readable_size})")

    report.append(f"\n\nTotal size of duplicate files: {bytes_to_human_readable(total_size)}")
    report.append(f"Total number of duplicate files: {total_file_num}")
    report.append(f"File with the most duplicates: {max_file_key[0]}(hash) {bytes_to_human_readable(max_file_key[1])}(size) {max_file_key[2]}(number)")
        
    print("\n".join(report))

def delete_identical_files(identical_dict: Dict[Tuple[str, int], List[Path]]):
    """
    åˆ é™¤æ–‡ä»¶å¤¹ä¸­ç›¸åŒå†…å®¹çš„æ–‡ä»¶ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :return: åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    report = []
    delete_size = 0
    for (hash_value,file_size), file_list in identical_dict.items():
        for file in tqdm(file_list, desc='Deleting files'):
            try:
                file.unlink()
                delete_size += file_size
                report.append(f"Deleted: {file}")
            except Exception as e:
                report.append(f"Error deleting {file}: {e}")

    report.append(f"\nTotal size of deleted files: {bytes_to_human_readable(delete_size)}")
    print("\n".join(report))

def move_identical_files(identical_dict: Dict[Tuple[str, int], List[Path]], target_folder: str | Path, size_threshold: int = None):
    """
    å°†ç›¸åŒå†…å®¹çš„æ–‡ä»¶ç§»åŠ¨åˆ°æŒ‡å®šçš„ç›®æ ‡æ–‡ä»¶å¤¹ã€‚

    :param identical_dict: ç›¸åŒæ–‡ä»¶çš„å­—å…¸ï¼Œç”± detect_identical_files å‡½æ•°è¿”å›ã€‚
    :param target_folder: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    :param size_threshold: æ–‡ä»¶å¤§å°é˜ˆå€¼ï¼Œåªæœ‰å¤§äºæ­¤é˜ˆå€¼çš„æ–‡ä»¶ä¼šè¢«ç§»åŠ¨ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä¸é™åˆ¶æ–‡ä»¶å¤§å°ã€‚
    :return: ç§»åŠ¨çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    target_folder = Path(target_folder)
    moved_files = []
    report = []

    for (hash_value, file_size), file_list in tqdm(identical_dict.items()):
        for file in file_list:
            if size_threshold is not None and file_size <= size_threshold:
                continue
            target_subfolder = target_folder / hash_value
            if not target_subfolder.exists():
                target_subfolder.mkdir(parents=True)
            target_path = target_subfolder / file.name

            # å¦‚æœæ–‡ä»¶å·²ç»åœ¨ç›®æ ‡è·¯å¾„ï¼Œè·³è¿‡
            if file.resolve() == target_path.resolve():
                report.append(f"File {file} is already in the target path.")
                continue
            
            # ä»…ä¿ç•™ä¸€ä¸ªç›¸åŒåç§°çš„æ–‡ä»¶
            if target_path.exists():
                report.append(f"File {target_path} already exists. Skipping {file}.")
                file.unlink()  # åˆ é™¤é‡å¤æ–‡ä»¶
                continue

            try:
                file.rename(target_path)
                moved_files.append((file, target_path))
                report.append(f"Moved: {file} -> {target_path}")
            except Exception as e:
                report.append(f"Error moving {file} to {target_path}: {e}")
    
    print("\n".join(report))

    return moved_files

def folder_to_file_path(folder_path: Path, file_extension: str) -> Path:
    """
    å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„ã€‚
    ä¾‹å¦‚ï¼Œç»™å®šæ–‡ä»¶å¤¹è·¯å¾„ '/home/user/folder1' å’Œæ–‡ä»¶æ‰©å±•å 'txt'ï¼Œå‡½æ•°ä¼šè¿”å›æ–‡ä»¶è·¯å¾„ '/home/user/folder1.txt'ã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :param file_extension: æ–‡ä»¶æ‰©å±•åã€‚
    :return: ä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„ã€‚
    """
    # è·å–æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•å’Œæ–‡ä»¶å¤¹åç§°
    folder_name = folder_path.stem  # è·å–æ–‡ä»¶å¤¹åç§°ï¼Œä¸å¸¦è·¯å¾„
    parent_dir = folder_path.parent  # è·å–æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•è·¯å¾„
    
    # ç”Ÿæˆä¸æ–‡ä»¶å¤¹åŒåçš„æ–‡ä»¶è·¯å¾„
    file_name = f"{folder_name}.{file_extension}"
    file_path = parent_dir / file_name
    
    return file_path

def replace_filenames(folder_path: Path | str, pattern: str, replacement: str):
    """
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ–‡ä»¶åä¸­çš„åŒ¹é…éƒ¨åˆ†ã€‚
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå°†å…¶ä¸­æ¯ä¸ªæ–‡ä»¶çš„æ–‡ä»¶åä¸­çš„åŒ¹é…å†…å®¹æ›¿æ¢ä¸º `replacement`ã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :param pattern: ç”¨äºåŒ¹é…æ–‡ä»¶åçš„æ­£åˆ™è¡¨è¾¾å¼ã€‚
    :param replacement: æ›¿æ¢åçš„æ–°å†…å®¹ã€‚
    """
    folder_path = Path(folder_path)  # å°†ä¼ å…¥çš„è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡
    for file in folder_path.glob('**/*'):  # ä½¿ç”¨glob('**/*')éå†ç›®å½•ä¸­çš„æ–‡ä»¶å’Œå­ç›®å½•
        if not file.is_file():  # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
            continue
        
        new_filename = re.sub(pattern, replacement, file.name)
        if new_filename == file.name:
            continue
        
        new_file_path = file.with_name(new_filename)  # ä½¿ç”¨with_nameæ–¹æ³•ç”Ÿæˆæ–°æ–‡ä»¶è·¯å¾„
        file.rename(new_file_path)  # é‡å‘½åæ–‡ä»¶

def get_folder_size(folder_path: Path | str) -> int:
    """
    è®¡ç®—æ–‡ä»¶å¤¹çš„å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•ï¼Œå¹¶è®¡ç®—å®ƒä»¬çš„å¤§å°æ€»å’Œã€‚

    :param folder_path: æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    :return: æ–‡ä»¶å¤¹çš„æ€»å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚
    """
    total_size = 0
    folder = Path(folder_path)
    for file in folder.rglob('*'):  # rglob('*') éå†æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•
        if file.is_file():
            total_size += file.stat().st_size  # è·å–æ–‡ä»¶å¤§å°
    return total_size